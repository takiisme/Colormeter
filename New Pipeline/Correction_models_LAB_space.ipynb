{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "tpm7sS9nPcO7"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from functools import partial\n",
        "from matplotlib.colors import rgb_to_hsv\n",
        "from scipy import stats\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.optimize import minimize\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "import color_conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ1jh4fz1igE"
      },
      "source": [
        "## In this file, I have tried different methods to correct in LAB space.\n",
        "## Method 0: Fixed White Scaling\n",
        "## Method 1: Using Polynomial Correction\n",
        "## Method 2: Using a 3 x 3 Matrix\n",
        "## Method 3: Using multiple inputs (adding pitch & roll).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "g9oElRwhPhbU"
      },
      "outputs": [],
      "source": [
        "# Read json file\n",
        "def readJsonData(JSON_FILE_PATH):\n",
        "  data = None\n",
        "  try:\n",
        "    with open(JSON_FILE_PATH, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    print(\"✅ JSON file loaded successfully.\")\n",
        "\n",
        "    metadata = data.get('metadata', {})\n",
        "    print(f\"\\n--- Session Metadata ---\")\n",
        "    for key, value in metadata.items():\n",
        "        print(f\"{key.ljust(20)}: {value}\")\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      print(f\"❌ ERROR: File not found at path: {JSON_FILE_PATH}\")\n",
        "      print(\"Please check the file path and ensure Google Drive is correctly mounted.\")\n",
        "  except json.JSONDecodeError:\n",
        "      print(\"❌ ERROR: Could not decode JSON. Ensure the file is valid.\")\n",
        "  return data\n",
        "\n",
        "# Preprocessing\n",
        "def preprocessData(data):\n",
        "  flat_data = []\n",
        "\n",
        "  # Extract metadata for easy merging later\n",
        "  session_metadata = data.get('metadata', {})\n",
        "  session_name = session_metadata.get('sessionName', 'Unknown Session')\n",
        "\n",
        "  # Iterate through each sample (color card)\n",
        "  for sample in data.get('data', []):\n",
        "      sample_number = sample.get('sampleNumber')\n",
        "\n",
        "      # Iterate through each measurement (1 to 10) within that sample\n",
        "      for capture_index, measurement in enumerate(sample.get('measurements', [])):\n",
        "\n",
        "          # Create a dictionary for the current row\n",
        "          row = {\n",
        "              'session_name': session_name,\n",
        "              'sample_number': sample_number,\n",
        "              'capture_index': capture_index, # 0 to 9\n",
        "              'lighting_condition': session_metadata.get('lightingCondition'),\n",
        "              'reflective_surface': session_metadata.get('useReflectiveSurface'),\n",
        "\n",
        "              # Sensor Data\n",
        "              'pitch': measurement['angles']['pitch'],\n",
        "              'roll': measurement['angles']['roll'],\n",
        "          }\n",
        "\n",
        "          # Extract Color Data (White and Color reticles, three radii each)\n",
        "\n",
        "          # White Reticle Captures\n",
        "          for radius in [0, 2, 4]:\n",
        "              capture_key = f'r{radius}'\n",
        "              color_data = measurement['white'].get(capture_key, {'r': 0, 'g': 0, 'b': 0})\n",
        "              row[f'white_r{radius}_R'] = color_data['r']\n",
        "              row[f'white_r{radius}_G'] = color_data['g']\n",
        "              row[f'white_r{radius}_B'] = color_data['b']\n",
        "\n",
        "          # Color Reticle Captures\n",
        "          for radius in [0, 2, 4]:\n",
        "              capture_key = f'r{radius}'\n",
        "              color_data = measurement['color'].get(capture_key, {'r': 0, 'g': 0, 'b': 0})\n",
        "              row[f'color_r{radius}_R'] = color_data['r']\n",
        "              row[f'color_r{radius}_G'] = color_data['g']\n",
        "              row[f'color_r{radius}_B'] = color_data['b']\n",
        "\n",
        "          flat_data.append(row)\n",
        "\n",
        "  # Convert the list of dictionaries to a Pandas DataFrame\n",
        "  df = pd.DataFrame(flat_data)\n",
        "\n",
        "  print(f\"\\n✅ Data flattened into DataFrame with {len(df)} rows (Total captures: 24 samples * 10 captures = 240 rows).\")\n",
        "  return df\n",
        "\n",
        "# ## 3. Initial Review and Visualization\n",
        "\n",
        "# Display the first few rows and the column types for verification.\n",
        "def displayDataFrameInfo(df):\n",
        "  print(\"\\n--- DataFrame Head (First 5 Rows) ---\")\n",
        "  print(df.head())\n",
        "\n",
        "  print(\"\\n--- DataFrame Information ---\")\n",
        "  print(df.info())\n",
        "\n",
        "  # ### 3.1 Check Sensor Variability\n",
        "\n",
        "  # This checks the pitch/roll stability across all 240 measurements.\n",
        "  print(\"\\n--- Sensor Angle Statistics ---\")\n",
        "  print(df[['pitch', 'roll']].describe())\n",
        "\n",
        "def merge_datasets_for_model(dfs):\n",
        "    \"\"\"\n",
        "    Vertically concatenate multiple datasets.\n",
        "    All rows are kept. Column names must be consistent.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dfs : list of pd.DataFrame\n",
        "        List of datasets with identical column structure\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Combined dataset\n",
        "    \"\"\"\n",
        "    merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
        "    return merged_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "PcqcwYAwPhYk"
      },
      "outputs": [],
      "source": [
        "def combineGroundTruth(df):\n",
        "  ground_truth_data = [\n",
        "      {'sample_number': 1,  'label': 'Dark Skin',      'gt__R': 115, 'gt__G': 82,  'gt__B': 69},\n",
        "      {'sample_number': 2,  'label': 'Light Skin',     'gt__R': 204, 'gt__G': 161, 'gt__B': 141},\n",
        "      {'sample_number': 3,  'label': 'Blue Sky',       'gt__R': 101, 'gt__G': 134, 'gt__B': 179},\n",
        "      {'sample_number': 4,  'label': 'Foliage',        'gt__R': 89,  'gt__G': 109, 'gt__B': 61},\n",
        "      {'sample_number': 5,  'label': 'Blue Flower',    'gt__R': 141, 'gt__G': 137, 'gt__B': 194},\n",
        "      {'sample_number': 6,  'label': 'Bluish Green',   'gt__R': 132, 'gt__G': 228, 'gt__B': 208},\n",
        "      {'sample_number': 7,  'label': 'Orange',         'gt__R': 249, 'gt__G': 118, 'gt__B': 35},\n",
        "      {'sample_number': 8,  'label': 'Purplish Blue',  'gt__R': 80,  'gt__G': 91,  'gt__B': 182},\n",
        "      {'sample_number': 9,  'label': 'Moderate Red',   'gt__R': 222, 'gt__G': 91,  'gt__B': 125},\n",
        "      {'sample_number': 10, 'label': 'Purple',         'gt__R': 91,  'gt__G': 63,  'gt__B': 123},\n",
        "      {'sample_number': 11, 'label': 'Yellow Green',   'gt__R': 173, 'gt__G': 232, 'gt__B': 91},\n",
        "      {'sample_number': 12, 'label': 'Orange Yellow',  'gt__R': 255, 'gt__G': 164, 'gt__B': 26},\n",
        "      {'sample_number': 13, 'label': 'Blue',           'gt__R': 44,  'gt__G': 56,  'gt__B': 142},\n",
        "      {'sample_number': 14, 'label': 'Green',          'gt__R': 74,  'gt__G': 148, 'gt__B': 81},\n",
        "      {'sample_number': 15, 'label': 'Red',            'gt__R': 179, 'gt__G': 42,  'gt__B': 50},\n",
        "      {'sample_number': 16, 'label': 'Yellow',         'gt__R': 250, 'gt__G': 226, 'gt__B': 21},\n",
        "      {'sample_number': 17, 'label': 'Magenta',        'gt__R': 191, 'gt__G': 81,  'gt__B': 160},\n",
        "      {'sample_number': 18, 'label': 'Cyan',           'gt__R': 6,   'gt__G': 142, 'gt__B': 172},\n",
        "      {'sample_number': 19, 'label': 'White',          'gt__R': 252, 'gt__G': 252, 'gt__B': 252},\n",
        "      {'sample_number': 20, 'label': 'Neutral 8',      'gt__R': 230, 'gt__G': 230, 'gt__B': 230},\n",
        "      {'sample_number': 21, 'label': 'Neutral 6.5',    'gt__R': 200, 'gt__G': 200, 'gt__B': 200},\n",
        "      {'sample_number': 22, 'label': 'Neutral 5',      'gt__R': 143, 'gt__G': 143, 'gt__B': 142},\n",
        "      {'sample_number': 23, 'label': 'Neutral 3.5',    'gt__R': 100, 'gt__G': 100, 'gt__B': 100},\n",
        "      {'sample_number': 24, 'label': 'Black',          'gt__R': 50,  'gt__G': 50,  'gt__B': 50},\n",
        "  ]\n",
        "  df_gt = pd.DataFrame(ground_truth_data)\n",
        "  df = pd.merge(df, df_gt, on='sample_number', how='outer')\n",
        "\n",
        "  return df, df_gt\n",
        "\n",
        "def generateFinalDataFrame(df_with_gt_columns):\n",
        "  # Calculate average color and corrected color values per sample_number\n",
        "  avg_cols_to_compute = [\n",
        "      'color_r0_R', 'color_r0_G', 'color_r0_B',\n",
        "      'correction_r0_R', 'correction_r0_G', 'correction_r0_B',\n",
        "      'color_r2_R', 'color_r2_G', 'color_r2_B',\n",
        "      'correction_r2_R', 'correction_r2_G', 'correction_r2_B',\n",
        "      'color_r4_R', 'color_r4_G', 'color_r4_B',\n",
        "      'correction_r4_R', 'correction_r4_G', 'correction_r4_B'\n",
        "  ]\n",
        "  df_avg = df_with_gt_columns.groupby('sample_number')[avg_cols_to_compute].mean().reset_index()\n",
        "\n",
        "  # Rename columns to 'avg_...' to clearly distinguish them\n",
        "  new_avg_columns_map = {col: 'avg_' + col for col in avg_cols_to_compute}\n",
        "  df_avg = df_avg.rename(columns=new_avg_columns_map)\n",
        "\n",
        "  # Merge the df (which now has ground truth) with the averaged color data\n",
        "  df_final_comparison = pd.merge(df_with_gt_columns, df_avg, on='sample_number', how='left')\n",
        "\n",
        "  return df_final_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM9XoJWJQCzU",
        "outputId": "0e556d3e-e507-4feb-f5d8-caa1dc30fbe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ JSON file loaded successfully.\n",
            "\n",
            "--- Session Metadata ---\n",
            "sessionName         : baisu1\n",
            "lightingCondition   : 0\n",
            "useReflectiveSurface: False\n",
            "dateTime            : 2025-11-19T15:01:46.558942\n",
            "\n",
            "✅ Data flattened into DataFrame with 240 rows (Total captures: 24 samples * 10 captures = 240 rows).\n"
          ]
        }
      ],
      "source": [
        "jsonFilePath = '../Data/Baisu1.json'\n",
        "data = readJsonData(jsonFilePath)\n",
        "df = preprocessData(data)\n",
        "df, _ = combineGroundTruth(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0RXNyH8y_uw"
      },
      "source": [
        "## Method 1: Using Polynomial Correction:  \n",
        "1. correction_r2_l = f1(color_r2_l)\n",
        "2. correction_r2_a = f2(color_r2_a)\n",
        "3. correction_r2_b = f3(color_r2_b).\n",
        "## Our task: Learn the degrees and coefficients of f1, f2, f3.\n",
        "## Conclusion: Compare with Fixed Scaling Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "XgVKybtkraO3"
      },
      "outputs": [],
      "source": [
        "def correctByPolynomial_optimizable(meas_l, meas_a, meas_b, coeffs_l, coeffs_a, coeffs_b):\n",
        "    \"\"\"Apply polynomials without clipping for optimization\"\"\"\n",
        "    corr_l = np.polyval(coeffs_l[::-1], meas_l) if len(coeffs_l) > 0 else meas_l\n",
        "    corr_a = np.polyval(coeffs_a[::-1], meas_a) if len(coeffs_a) > 0 else meas_a\n",
        "    corr_b = np.polyval(coeffs_b[::-1], meas_b) if len(coeffs_b) > 0 else meas_b\n",
        "    return corr_l, corr_a, corr_b\n",
        "\n",
        "def calculateSingleChannelLoss(coeffs, measured_values, gt_values, degree, channel=None):\n",
        "    def _apply_single_channel_polynomial(meas, ch_coeffs):\n",
        "        return np.polyval(ch_coeffs[::-1], meas)\n",
        "\n",
        "    corrected_values = _apply_single_channel_polynomial(measured_values, coeffs)\n",
        "    data_loss = np.mean(np.abs(gt_values - corrected_values))\n",
        "\n",
        "    # Add boundary penalty\n",
        "    if channel == 'l':\n",
        "        boundary_penalty = np.mean((corrected_values < 2) | (corrected_values > 98)) * 1000\n",
        "    elif channel in ['a', 'b']:\n",
        "        boundary_penalty = np.mean((corrected_values < -122) | (corrected_values > 123)) * 1000\n",
        "    # L1 coefficient penalty\n",
        "    coeff_penalty = 0.001 * np.sum(np.abs(coeffs))\n",
        "\n",
        "    return data_loss + boundary_penalty + coeff_penalty\n",
        "\n",
        "def get_smart_initial_guess_single_channel(measured_series, gt_series, degree):\n",
        "    \"\"\"Get reasonable initial coefficients for a single channel using linear regression\"\"\"\n",
        "    X = measured_series.values\n",
        "    y = gt_series.values\n",
        "\n",
        "    try:\n",
        "        if degree == 0:\n",
        "            coeffs = [np.mean(y)]\n",
        "        else:\n",
        "            # Polynomial fit (coeffs are in decreasing order of power)\n",
        "            poly_coeffs = np.polyfit(X, y, degree)\n",
        "            coeffs = poly_coeffs[::-1].tolist()  # Convert to our format (lowest degree first)\n",
        "    except Exception:\n",
        "        # Fallback: identity mapping coefficients or mean if fit fails\n",
        "        if degree == 0:\n",
        "            coeffs = [np.mean(y)]  # Use mean if it fails for degree 0\n",
        "        elif degree == 1:\n",
        "            coeffs = [0.0, 1.0]  # Identity: y = x (c0=0, c1=1)\n",
        "        else:\n",
        "            coeffs = [0.0] * (degree + 1)\n",
        "            if degree >= 1: # Set linear term to 1 for higher degrees as a starting point\n",
        "                coeffs[1] = 1.0\n",
        "    return np.array(coeffs)\n",
        "\n",
        "def get_smart_initial_guess(df, degrees):\n",
        "    \"\"\"Get reasonable initial coefficients using linear regression\"\"\"\n",
        "    initial_guess = []\n",
        "\n",
        "    for channel, degree in degrees.items():\n",
        "        X = df[f'color_r4_{channel}'].values\n",
        "        y = df[f'gt__{channel}'].values\n",
        "\n",
        "        # Use polyfit to get reasonable starting point\n",
        "        try:\n",
        "            if degree == 0:\n",
        "                coeffs = [np.mean(y)]\n",
        "            else:\n",
        "                poly_coeffs = np.polyfit(X, y, degree)\n",
        "                coeffs = poly_coeffs[::-1].tolist()  # Convert to our format (lowest degree first)\n",
        "        except:\n",
        "            if degree == 0:\n",
        "                coeffs = [128.0]  # Middle value\n",
        "            elif degree == 1:\n",
        "                coeffs = [0.0, 1.0]  # Identity: y = x\n",
        "            else:\n",
        "                coeffs = [0.0] * (degree + 1)\n",
        "                coeffs[1] = 1.0  # Linear term = 1\n",
        "\n",
        "        initial_guess.extend(coeffs)\n",
        "\n",
        "    return np.array(initial_guess)\n",
        "\n",
        "def optimizeSingleChannelCoefficients(df, channel, degree):\n",
        "    \"\"\"Optimize coefficients for a single channel\"\"\"\n",
        "    print(f\"Optimizing polynomial for {channel} channel with degree {degree}\")\n",
        "\n",
        "    measured_values = df[f'color_r4_{channel}'].values\n",
        "    gt_values = df[f'gt__{channel}'].values\n",
        "\n",
        "    # Get smart initial guess\n",
        "    initial_guess = get_smart_initial_guess_single_channel(df[f'color_r4_{channel}'], df[f'gt__{channel}'], degree)\n",
        "    print(f\"Initial guess for {channel}: {initial_guess}\")\n",
        "\n",
        "    # Define bounds for coefficients\n",
        "    bounds = [(-1000, 1000)] * (degree + 1)\n",
        "\n",
        "    # Use a partial function to pass fixed arguments to the loss function\n",
        "    loss_func = partial(calculateSingleChannelLoss, measured_values=measured_values, gt_values=gt_values, degree=degree, channel=channel)\n",
        "\n",
        "    # Optimize\n",
        "    result = minimize(\n",
        "        loss_func,\n",
        "        initial_guess,\n",
        "        method='L-BFGS-B',\n",
        "        bounds=bounds,\n",
        "        options={'maxiter': 1000, 'ftol': 1e-8}\n",
        "    )\n",
        "\n",
        "    optimal_coeffs = result.x\n",
        "\n",
        "    dummy_meas = np.zeros_like(measured_values)\n",
        "\n",
        "    if channel == 'l':\n",
        "        final_corr_l, _, _ = correctByPolynomial_optimizable(measured_values, dummy_meas, dummy_meas, optimal_coeffs, np.array([0.0]), np.array([0.0]))\n",
        "        final_corrected_values = np.clip(final_corr_l, 0, 100)\n",
        "    elif channel == 'a':\n",
        "        _, final_corr_a, _ = correctByPolynomial_optimizable(dummy_meas, measured_values, dummy_meas, np.array([0.0]), optimal_coeffs, np.array([0.0]))\n",
        "        final_corrected_values = np.clip(final_corr_a, -128, 127)\n",
        "    elif channel == 'b':\n",
        "        _, _, final_corr_b = correctByPolynomial_optimizable(dummy_meas, dummy_meas, measured_values, np.array([0.0]), np.array([0.0]), optimal_coeffs)\n",
        "        final_corrected_values = np.clip(final_corr_b, -128, 127)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid channel\")\n",
        "\n",
        "    final_mse = mean_squared_error(gt_values, final_corrected_values)\n",
        "\n",
        "    print(f\"Final MSE for {channel}: {final_mse:.2f}\")\n",
        "    print(f\"{channel} coefficients: {optimal_coeffs}\")\n",
        "    print(f\"Value ranges - {channel}: [{final_corrected_values.min()}, {final_corrected_values.max()}]\")\n",
        "\n",
        "    return {\n",
        "        'coeffs': optimal_coeffs.tolist(),\n",
        "        'mse': final_mse\n",
        "    }\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def calculateUnifiedLoss(all_coeffs, df, degrees):\n",
        "    \"\"\"\n",
        "    Calculate loss for all channels simultaneously\n",
        "    with penalty for boundary solutions\n",
        "    \"\"\"\n",
        "    # Split coefficients for each channel\n",
        "    n_l = degrees['l'] + 1\n",
        "    n_a = degrees['a'] + 1\n",
        "    n_b = degrees['b'] + 1\n",
        "\n",
        "    coeffs_l = all_coeffs[:n_l]\n",
        "    coeffs_a = all_coeffs[n_l:n_l+n_a]\n",
        "    coeffs_b = all_coeffs[n_l+n_a:]\n",
        "\n",
        "    # Get corrected values\n",
        "    corr_l, corr_a, corr_b = correctByPolynomial_optimizable(\n",
        "        df['color_r4_l'].values,\n",
        "        df['color_r4_a'].values,\n",
        "        df['color_r4_b'].values,\n",
        "        coeffs_l, coeffs_a, coeffs_b\n",
        "    )\n",
        "\n",
        "    # Calculate MSE for each channel\n",
        "    mse_l = mean_squared_error(df['gt__l'].values, corr_l)\n",
        "    mse_a = mean_squared_error(df['gt__a'].values, corr_a)\n",
        "    mse_b = mean_squared_error(df['gt__b'].values, corr_b)\n",
        "    # Total MSE (weighted equally)\n",
        "    total_mse = (mse_l + mse_a + mse_b) / 3.0\n",
        "    # **CRITICAL: Add penalty for boundary solutions**\n",
        "    boundary_penalty = 0.0\n",
        "\n",
        "    \n",
        "    penalty_l = np.mean((corr_l < 2) | (corr_l > 98)) * 1000\n",
        "    penalty_a = np.mean((corr_a < -122) | (corr_a > 123)) * 1000\n",
        "    penalty_b = np.mean((corr_b < -122) | (corr_b > 123)) * 1000\n",
        "\n",
        "    boundary_penalty = penalty_l + penalty_a + penalty_b\n",
        "\n",
        "    # Penalize extreme coefficients to prevent overfitting\n",
        "    coeff_penalty = 0.001 * (np.sum(np.abs(coeffs_l)) + np.sum(np.abs(coeffs_a)) + np.sum(np.abs(coeffs_b)))\n",
        "\n",
        "    return total_mse + boundary_penalty + coeff_penalty\n",
        "\n",
        "def optimizeUnifiedCoefficients(df, degrees):\n",
        "    \"\"\"Optimize all channels together with the same degree\"\"\"\n",
        "    print(f\"Optimizing unified polynomials with degrees L:{degrees['l']}, A:{degrees['a']}, B:{degrees['b']}\")\n",
        "\n",
        "    # Get smart initial guess\n",
        "    initial_guess = get_smart_initial_guess(df, degrees)\n",
        "\n",
        "    print(f\"Initial guess: {initial_guess}\")\n",
        "\n",
        "    # Define bounds to prevent extreme coefficients\n",
        "    bounds = []\n",
        "    total_coeffs = (degrees['l'] + 1) + (degrees['a'] + 1) + (degrees['b'] + 1)\n",
        "    # Reasonable bounds for coefficients\n",
        "    for i in range(total_coeffs):\n",
        "        # Allow some flexibility but prevent extreme values\n",
        "        bounds.append((-1000, 1000))\n",
        "\n",
        "    # Optimize with constraints\n",
        "    result = minimize(\n",
        "        calculateUnifiedLoss,\n",
        "        initial_guess,\n",
        "        args=(df, degrees),\n",
        "        method='L-BFGS-B',  # Handles bounds\n",
        "        bounds=bounds,\n",
        "        options={'maxiter': 1000, 'ftol': 1e-8}\n",
        "    )\n",
        "\n",
        "    # Split the optimized coefficients\n",
        "    n_l = degrees['l'] + 1\n",
        "    n_a = degrees['a'] + 1\n",
        "    n_b = degrees['b'] + 1\n",
        "\n",
        "    optimal_coeffs_l = result.x[:n_l]\n",
        "    optimal_coeffs_a = result.x[n_l:n_l+n_a]\n",
        "    optimal_coeffs_b = result.x[n_l+n_a:]\n",
        "\n",
        "    # Calculate final performance\n",
        "    final_r, final_g, final_b = correctByPolynomial_optimizable(\n",
        "        df['color_r4_l'].values,\n",
        "        df['color_r4_a'].values,\n",
        "        df['color_r4_b'].values,\n",
        "        optimal_coeffs_l, optimal_coeffs_a, optimal_coeffs_b\n",
        "    )\n",
        "\n",
        "    # Apply clipping only for final output\n",
        "    final_l = np.clip(final_l, 0, 100)\n",
        "    final_a = np.clip(final_a, -128, 127)\n",
        "    final_b = np.clip(final_b, -128, 127)\n",
        "\n",
        "    mse_l = mean_squared_error(df['gt__l'].values, final_l)\n",
        "    mse_a = mean_squared_error(df['gt__a'].values, final_a)\n",
        "    mse_b = mean_squared_error(df['gt__b'].values, final_b)\n",
        "    avg_mse = (mse_l + mse_a + mse_b) / 3.0\n",
        "\n",
        "    print(f\"Final MSE - L: {mse_l:.2f}, A: {mse_a:.2f}, B: {mse_b:.2f}, Avg: {avg_mse:.2f}\")\n",
        "    print(f\"L coefficients: {optimal_coeffs_l}\")\n",
        "    print(f\"A coefficients: {optimal_coeffs_a}\")\n",
        "    print(f\"B coefficients: {optimal_coeffs_b}\")\n",
        "\n",
        "    # Check value ranges\n",
        "    print(f\"Value ranges - L: [{final_l.min()}, {final_l.max()}], A: [{final_a.min()}, {final_a.max()}], B: [{final_b.min()}, {final_b.max()}]\")\n",
        "\n",
        "    return {\n",
        "        'l': optimal_coeffs_l.tolist(),\n",
        "        'a': optimal_coeffs_a.tolist(),\n",
        "        'b': optimal_coeffs_b.tolist(),\n",
        "        'mse': avg_mse,\n",
        "        'mse_l': mse_l,\n",
        "        'mse_a': mse_a,\n",
        "        'mse_b': mse_b\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPO80CP0P0Yc",
        "outputId": "981891da-bb8b-421d-e731-cd534601fcd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting individual channel optimization...\n",
            "Optimizing channels individually (max 10 degrees per channel)\n",
            "\n",
            "==================================================\n",
            "OPTIMIZING CHANNEL l\n",
            "==================================================\n",
            "\n",
            "Testing degree 1 for channel l\n",
            "*** NEW BEST for l: MSE = 29.5833 at degree 1 ***\n",
            "\n",
            "Testing degree 2 for channel l\n",
            "*** NEW BEST for l: MSE = 28.6321 at degree 2 ***\n",
            "\n",
            "Testing degree 3 for channel l\n",
            "*** NEW BEST for l: MSE = 28.4930 at degree 3 ***\n",
            "\n",
            "Testing degree 4 for channel l\n",
            "*** NEW BEST for l: MSE = 27.6972 at degree 4 ***\n",
            "\n",
            "Testing degree 5 for channel l\n",
            "No improvement. Current best MSE: 27.6972\n",
            "\n",
            "Testing degree 6 for channel l\n",
            "No improvement. Current best MSE: 27.6972\n",
            "\n",
            "Testing degree 7 for channel l\n",
            "*** NEW BEST for l: MSE = 27.4415 at degree 7 ***\n",
            "\n",
            "Testing degree 8 for channel l\n",
            "*** NEW BEST for l: MSE = 26.7536 at degree 8 ***\n",
            "\n",
            "Testing degree 9 for channel l\n",
            "*** NEW BEST for l: MSE = 26.6788 at degree 9 ***\n",
            "\n",
            "Testing degree 10 for channel l\n",
            "*** NEW BEST for l: MSE = 26.6757 at degree 10 ***\n",
            "\n",
            "--- BEST RESULT FOR CHANNEL l ---\n",
            "Best degree: 10\n",
            "Best MSE: 26.6757\n",
            "Best coefficients: [496.89904455531666, -147.92170759382503, 19.305797090374337, -1.412696710931534, 0.0649494861791414, -0.0019608212431087234, 3.929287318744045e-05, -5.14789959333101e-07, 4.2094443130819325e-09, -1.9342777662847026e-11, 3.77599375318344e-14]\n",
            "\n",
            "==================================================\n",
            "OPTIMIZING CHANNEL a\n",
            "==================================================\n",
            "\n",
            "Testing degree 1 for channel a\n",
            "*** NEW BEST for a: MSE = 30.3324 at degree 1 ***\n",
            "\n",
            "Testing degree 2 for channel a\n",
            "*** NEW BEST for a: MSE = 28.9931 at degree 2 ***\n",
            "\n",
            "Testing degree 3 for channel a\n",
            "*** NEW BEST for a: MSE = 25.7822 at degree 3 ***\n",
            "\n",
            "Testing degree 4 for channel a\n",
            "*** NEW BEST for a: MSE = 25.5583 at degree 4 ***\n",
            "\n",
            "Testing degree 5 for channel a\n",
            "*** NEW BEST for a: MSE = 25.1379 at degree 5 ***\n",
            "\n",
            "Testing degree 6 for channel a\n",
            "*** NEW BEST for a: MSE = 25.0384 at degree 6 ***\n",
            "\n",
            "Testing degree 7 for channel a\n",
            "*** NEW BEST for a: MSE = 24.8738 at degree 7 ***\n",
            "\n",
            "Testing degree 8 for channel a\n",
            "*** NEW BEST for a: MSE = 24.8577 at degree 8 ***\n",
            "\n",
            "Testing degree 9 for channel a\n",
            "*** NEW BEST for a: MSE = 24.8423 at degree 9 ***\n",
            "\n",
            "Testing degree 10 for channel a\n",
            "*** NEW BEST for a: MSE = 24.5909 at degree 10 ***\n",
            "\n",
            "--- BEST RESULT FOR CHANNEL a ---\n",
            "Best degree: 10\n",
            "Best MSE: 24.5909\n",
            "Best coefficients: [2.9918866964095683, 1.3311645203928175, 0.0030280219413547273, -0.0004896384191828132, -3.788465159748172e-05, 3.2477215996455568e-06, 4.335122257139332e-08, -4.7579439414217555e-09, 1.574717497537788e-11, 1.976735639241149e-12, -2.2263440963564938e-14]\n",
            "\n",
            "==================================================\n",
            "OPTIMIZING CHANNEL b\n",
            "==================================================\n",
            "\n",
            "Testing degree 1 for channel b\n",
            "*** NEW BEST for b: MSE = 38.5601 at degree 1 ***\n",
            "\n",
            "Testing degree 2 for channel b\n",
            "*** NEW BEST for b: MSE = 37.3611 at degree 2 ***\n",
            "\n",
            "Testing degree 3 for channel b\n",
            "*** NEW BEST for b: MSE = 35.9559 at degree 3 ***\n",
            "\n",
            "Testing degree 4 for channel b\n",
            "*** NEW BEST for b: MSE = 35.9493 at degree 4 ***\n",
            "\n",
            "Testing degree 5 for channel b\n",
            "*** NEW BEST for b: MSE = 34.2022 at degree 5 ***\n",
            "\n",
            "Testing degree 6 for channel b\n",
            "*** NEW BEST for b: MSE = 33.0608 at degree 6 ***\n",
            "\n",
            "Testing degree 7 for channel b\n",
            "*** NEW BEST for b: MSE = 31.1936 at degree 7 ***\n",
            "\n",
            "Testing degree 8 for channel b\n",
            "*** NEW BEST for b: MSE = 30.8155 at degree 8 ***\n",
            "\n",
            "Testing degree 9 for channel b\n",
            "*** NEW BEST for b: MSE = 27.1353 at degree 9 ***\n",
            "\n",
            "Testing degree 10 for channel b\n",
            "*** NEW BEST for b: MSE = 26.3720 at degree 10 ***\n",
            "\n",
            "--- BEST RESULT FOR CHANNEL b ---\n",
            "Best degree: 10\n",
            "Best MSE: 26.3720\n",
            "Best coefficients: [-0.5406212364063595, 1.7977590840935533, -0.05507037286081239, -0.0024962937162982136, 0.00016272134659017646, 1.609268616426263e-06, -1.6391698553780845e-07, 1.1191148185217662e-09, 4.7721006403520665e-11, -8.587113001458209e-13, 4.138156371516773e-15]\n",
            "\n",
            "============================================================\n",
            "FINAL INDIVIDUAL OPTIMIZATION RESULTS:\n",
            "Best degrees - L:10, A:10, B:10\n",
            "Channel MSE - L:26.6757, A:24.5909, B:26.3720\n",
            "Average MSE: 25.8795\n",
            "l coefficients: [496.89904455531666, -147.92170759382503, 19.305797090374337, -1.412696710931534, 0.0649494861791414, -0.0019608212431087234, 3.929287318744045e-05, -5.14789959333101e-07, 4.2094443130819325e-09, -1.9342777662847026e-11, 3.77599375318344e-14]\n",
            "a coefficients: [2.9918866964095683, 1.3311645203928175, 0.0030280219413547273, -0.0004896384191828132, -3.788465159748172e-05, 3.2477215996455568e-06, 4.335122257139332e-08, -4.7579439414217555e-09, 1.574717497537788e-11, 1.976735639241149e-12, -2.2263440963564938e-14]\n",
            "b coefficients: [-0.5406212364063595, 1.7977590840935533, -0.05507037286081239, -0.0024962937162982136, 0.00016272134659017646, 1.609268616426263e-06, -1.6391698553780845e-07, 1.1191148185217662e-09, 4.7721006403520665e-11, -8.587113001458209e-13, 4.138156371516773e-15]\n",
            "============================================================\n",
            "\n",
            "Final coefficients ready for use:\n",
            "L: [496.89904455531666, -147.92170759382503, 19.305797090374337, -1.412696710931534, 0.0649494861791414, -0.0019608212431087234, 3.929287318744045e-05, -5.14789959333101e-07, 4.2094443130819325e-09, -1.9342777662847026e-11, 3.77599375318344e-14]\n",
            "A: [2.9918866964095683, 1.3311645203928175, 0.0030280219413547273, -0.0004896384191828132, -3.788465159748172e-05, 3.2477215996455568e-06, 4.335122257139332e-08, -4.7579439414217555e-09, 1.574717497537788e-11, 1.976735639241149e-12, -2.2263440963564938e-14]\n",
            "B: [-0.5406212364063595, 1.7977590840935533, -0.05507037286081239, -0.0024962937162982136, 0.00016272134659017646, 1.609268616426263e-06, -1.6391698553780845e-07, 1.1191148185217662e-09, 4.7721006403520665e-11, -8.587113001458209e-13, 4.138156371516773e-15]\n"
          ]
        }
      ],
      "source": [
        "def findBestPolynomials_individual(df, max_degree=10):\n",
        "    \"\"\"\n",
        "    Find the best polynomial degrees for each channel individually\n",
        "    Only tests max_degree combinations per channel (30 total for max_degree=10)\n",
        "    \"\"\"\n",
        "    print(f\"Optimizing channels individually (max {max_degree} degrees per channel)\")\n",
        "\n",
        "    best_results = {}\n",
        "    best_degrees = {}\n",
        "\n",
        "    # Optimize each channel separately\n",
        "    for channel in ['l', 'a', 'b']:\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"OPTIMIZING CHANNEL {channel}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "        channel_best_result = None\n",
        "        channel_best_degree = None\n",
        "\n",
        "        # Try different degrees for this channel only\n",
        "        for degree in range(1, max_degree + 1):\n",
        "            print(f\"\\nTesting degree {degree} for channel {channel}\")\n",
        "\n",
        "            try:\n",
        "                # Use your original single-channel optimization\n",
        "                result = optimizeSingleChannel(df, channel, degree)\n",
        "\n",
        "                if channel_best_result is None or result['mse'] < channel_best_result['mse']:\n",
        "                    channel_best_result = result\n",
        "                    channel_best_degree = degree\n",
        "                    print(f\"*** NEW BEST for {channel}: MSE = {result['mse']:.4f} at degree {degree} ***\")\n",
        "                else:\n",
        "                    print(f\"No improvement. Current best MSE: {channel_best_result['mse']:.4f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Failed for {channel} degree {degree}: {e}\")\n",
        "                continue\n",
        "\n",
        "        # Store the best result for this channel\n",
        "        best_results[channel] = channel_best_result\n",
        "        best_degrees[channel] = channel_best_degree\n",
        "\n",
        "        print(f\"\\n--- BEST RESULT FOR CHANNEL {channel} ---\")\n",
        "        print(f\"Best degree: {channel_best_degree}\")\n",
        "        print(f\"Best MSE: {channel_best_result['mse']:.4f}\")\n",
        "        print(f\"Best coefficients: {channel_best_result['coefficients']}\")\n",
        "\n",
        "    # Combine results\n",
        "    final_result = {\n",
        "        'l': best_results['l']['coefficients'],\n",
        "        'a': best_results['a']['coefficients'],\n",
        "        'b': best_results['b']['coefficients'],\n",
        "        'mse_l': best_results['l']['mse'],\n",
        "        'mse_a': best_results['a']['mse'],\n",
        "        'mse_b': best_results['b']['mse'],\n",
        "        'avg_mse': (best_results['l']['mse'] + best_results['a']['mse'] + best_results['b']['mse']) / 3.0\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"FINAL INDIVIDUAL OPTIMIZATION RESULTS:\")\n",
        "    print(f\"Best degrees - L:{best_degrees['l']}, A:{best_degrees['a']}, B:{best_degrees['b']}\")\n",
        "    print(f\"Channel MSE - L:{final_result['mse_l']:.4f}, A:{final_result['mse_a']:.4f}, B:{final_result['mse_b']:.4f}\")\n",
        "    print(f\"Average MSE: {final_result['avg_mse']:.4f}\")\n",
        "    print(f\"l coefficients: {final_result['l']}\")\n",
        "    print(f\"a coefficients: {final_result['a']}\")\n",
        "    print(f\"b coefficients: {final_result['b']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return final_result, best_degrees\n",
        "\n",
        "def optimizeSingleChannel(df, channel, degree):\n",
        "    \"\"\"\n",
        "    Optimize polynomial for a single channel\n",
        "    This should be your original single-channel optimization function\n",
        "    \"\"\"\n",
        "    # Extract data for this specific channel\n",
        "    meas_col = f'color_r4_{channel}'\n",
        "    gt_col = f'gt__{channel}'\n",
        "\n",
        "    X_data = df[meas_col].values\n",
        "    y_true = df[gt_col].values\n",
        "\n",
        "    # Number of coefficients for this degree\n",
        "    n_coeffs = degree + 1\n",
        "\n",
        "    # Smart initial guess using polyfit\n",
        "    try:\n",
        "        initial_guess = np.polyfit(X_data, y_true, degree)[::-1]  # Reverse for our format\n",
        "    except:\n",
        "        # Fallback to identity mapping\n",
        "        initial_guess = [0.0] * n_coeffs\n",
        "        if degree >= 1:\n",
        "            initial_guess[1] = 1.0  # Linear term = 1\n",
        "\n",
        "    # Define bounds to prevent extreme coefficients\n",
        "    bounds = [(-1000, 1000) for _ in range(n_coeffs)]\n",
        "\n",
        "    # Optimize this single channel\n",
        "    result = minimize(\n",
        "        calculateSingleChannelLoss,\n",
        "        initial_guess,\n",
        "        args=(X_data, y_true, degree, channel),\n",
        "        method='L-BFGS-B',\n",
        "        bounds=bounds,\n",
        "        options={'maxiter': 500, 'ftol': 1e-8}\n",
        "    )\n",
        "\n",
        "    # Get final corrected values\n",
        "    optimal_coeffs = result.x\n",
        "    y_pred = evaluatePolynomial(X_data, optimal_coeffs, degree)\n",
        "\n",
        "    # Apply clipping for final evaluation\n",
        "    if channel == 'l':\n",
        "        y_pred_clipped = np.clip(y_pred, 0, 100)\n",
        "    elif channel in ['a', 'b']:\n",
        "        y_pred_clipped = np.clip(y_pred, -128, 127)\n",
        "    final_mse = mean_squared_error(y_true, y_pred_clipped)\n",
        "\n",
        "    return {\n",
        "        'coefficients': optimal_coeffs.tolist(),\n",
        "        'mse': final_mse,\n",
        "        'success': result.success\n",
        "    }\n",
        "\n",
        "def calculateSingleChannelLoss(coeffs, X_data, y_true, degree, channel):\n",
        "    \"\"\"Calculate loss for a single channel\"\"\"\n",
        "    y_pred = evaluatePolynomial(X_data, coeffs, degree)\n",
        "\n",
        "    # MSE\n",
        "    mse = np.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "\n",
        "    # Add boundary penalty\n",
        "    if channel == 'l':\n",
        "        boundary_penalty = np.mean((y_pred < 2) | (y_pred > 98)) * 1000\n",
        "    elif channel in ['a', 'b']:\n",
        "        boundary_penalty = np.mean((y_pred < -122) | (y_pred > 123)) * 1000\n",
        "    # Regularization to prevent overfitting\n",
        "    reg_penalty = 0.001 * np.sum(np.array(coeffs) ** 2)\n",
        "\n",
        "    return mse + boundary_penalty + reg_penalty\n",
        "\n",
        "def evaluatePolynomial(X, coeffs, degree):\n",
        "    \"\"\"Evaluate polynomial without clipping\"\"\"\n",
        "    y_pred = np.zeros_like(X, dtype=float)\n",
        "    for k in range(degree + 1):\n",
        "        y_pred += coeffs[k] * (X ** k)\n",
        "    return y_pred\n",
        "\n",
        "# Convert RGB columns to LAB \n",
        "\n",
        "color_conversion.convert_rgb_cols(df, prefix='gt__', to='lab')\n",
        "color_conversion.convert_rgb_cols(df, prefix='color_r0_', to='lab')\n",
        "color_conversion.convert_rgb_cols(df, prefix='color_r2_', to='lab')\n",
        "color_conversion.convert_rgb_cols(df, prefix='color_r4_', to='lab')\n",
        "\n",
        "# Run the individual optimization\n",
        "print(\"Starting individual channel optimization...\")\n",
        "best_result, best_degrees = findBestPolynomials_individual(df, max_degree=10)\n",
        "\n",
        "# Extract the final coefficients\n",
        "best_coeffs_l = best_result['l']\n",
        "best_coeffs_a = best_result['a']\n",
        "best_coeffs_b = best_result['b']\n",
        "\n",
        "print(f\"\\nFinal coefficients ready for use:\")\n",
        "print(f\"L: {best_coeffs_l}\")\n",
        "print(f\"A: {best_coeffs_a}\")\n",
        "print(f\"B: {best_coeffs_b}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fWy7iwAP0Vs",
        "outputId": "d9655d5d-f0c3-4926-e995-d9e5b68a777e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results:\n",
            "L range: [20.201690948533326, 99.37033614827703] -> Target: ~[20.78777714137035, 98.96399275988765]\n",
            "A range: [-42.40867709031532, 56.03994449725121] -> Target: ~[-40.170075615230786, 54.419961406329016]\n",
            "B range: [-51.713096983638415, 88.19134506059333] -> Target: ~[-49.740030225081625, 86.64778896041103]\n"
          ]
        }
      ],
      "source": [
        "def validate_correction(df, coeffs_l, coeffs_a, coeffs_b):\n",
        "    \"\"\"Validate the correction and show results\"\"\"\n",
        "    corr_l, corr_a, corr_b = correctByPolynomial_optimizable(\n",
        "        df['color_r4_l'].values,\n",
        "        df['color_r4_a'].values,\n",
        "        df['color_r4_b'].values,\n",
        "        coeffs_l, coeffs_a, coeffs_b\n",
        "    )\n",
        "\n",
        "    # Apply clipping for final output\n",
        "    corr_l = np.clip(corr_l, 0, 100)\n",
        "    corr_a = np.clip(corr_a, -128, 127)\n",
        "    corr_b = np.clip(corr_b, -128, 127)\n",
        "\n",
        "    print(\"Validation Results:\")\n",
        "    print(f\"L range: [{corr_l.min()}, {corr_l.max()}] -> Target: ~[{df['gt__l'].min()}, {df['gt__l'].max()}]\")\n",
        "    print(f\"A range: [{corr_a.min()}, {corr_a.max()}] -> Target: ~[{df['gt__a'].min()}, {df['gt__a'].max()}]\")\n",
        "    print(f\"B range: [{corr_b.min()}, {corr_b.max()}] -> Target: ~[{df['gt__b'].min()}, {df['gt__b'].max()}]\")\n",
        "\n",
        "    # Check if we have the boundary problem\n",
        "    if corr_l.min() == 0 and corr_l.max() == 100:\n",
        "        print(\"WARNING: L channel has boundary values!\")\n",
        "    if corr_a.min() == -128 and corr_a.max() == 127:\n",
        "        print(\"WARNING: A channel has boundary values!\")\n",
        "    if corr_b.min() == -128 and corr_b.max() == 127:\n",
        "        print(\"WARNING: B channel has boundary values!\")\n",
        "\n",
        "    return corr_l, corr_a, corr_b\n",
        "\n",
        "# Validate the results\n",
        "final_l, final_a, final_b = validate_correction(df, best_coeffs_l, best_coeffs_a, best_coeffs_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THg03tmuP0Tc",
        "outputId": "a9aabd4c-0c9d-4c7c-db34-d3e45d66d9f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correction functions redefined for flexibility.\n"
          ]
        }
      ],
      "source": [
        "def correctByFixedWhiteScaling(ref_l, ref_a, ref_b, meas_l, meas_a, meas_b):\n",
        "  # Apply scaling correction based on a fixed white reference\n",
        "  # ---- L channel: scale to white (L = 100) ----\n",
        "  scale_l = 100.0 / max(ref_l, 1e-6)\n",
        "  corr_l = meas_l * scale_l\n",
        "  corr_a = meas_a - ref_a\n",
        "  corr_b = meas_b - ref_b\n",
        "\n",
        "  # ---- clip to valid Lab range ----\n",
        "  corr_l = np.clip(corr_l, 0.0, 100.0)\n",
        "  corr_a = np.clip(corr_a, -128.0, 127.0)\n",
        "  corr_b = np.clip(corr_b, -128.0, 127.0)\n",
        "\n",
        "  return corr_l, corr_a, corr_b\n",
        "\n",
        "def correctByPolynomial(meas_val, coeffs):\n",
        "  corr_val = np.polyval(coeffs[::-1], meas_val)\n",
        "  return corr_val\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "# This function will be passed to df.apply and dispatches to the correct method\n",
        "def apply_correction_dispatcher(row, color_prefix, radius, correction_type, coeffs_l=None, coeffs_a=None, coeffs_b=None, ref_white_l=None, ref_white_a=None, ref_white_b=None):\n",
        "    meas_l = row[f'{color_prefix}_l']\n",
        "    meas_a = row[f'{color_prefix}_a']\n",
        "    meas_b = row[f'{color_prefix}_b']\n",
        "\n",
        "    if correction_type == 'white_scaling':\n",
        "        # Use the fixed white reference for scaling\n",
        "        ref_l = 70.71 # Default from original apply_correction\n",
        "        ref_a = 0.39\n",
        "        ref_b = 14.68\n",
        "        corr_l, corr_a, corr_b = correctByFixedWhiteScaling(ref_l, ref_a, ref_b, meas_l, meas_a, meas_b)\n",
        "    elif correction_type == 'polynomial':\n",
        "        corr_l = correctByPolynomial(meas_l, coeffs_l)\n",
        "        corr_a = correctByPolynomial(meas_a, coeffs_a)\n",
        "        corr_b = correctByPolynomial(meas_b, coeffs_b)\n",
        "        # Apply clipping here as correctByPolynomial doesn't do it\n",
        "        corr_l = np.clip(corr_l, 0, 100)\n",
        "        corr_a = np.clip(corr_a, -128, 127)\n",
        "        corr_b = np.clip(corr_b, -128, 127)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown correction_type: {correction_type}\")\n",
        "\n",
        "    return pd.Series([corr_l, corr_a, corr_b])\n",
        "\n",
        "# Main function to apply corrections to DataFrame\n",
        "def correctRGB(df, correction_type, coeffs_l=None, coeffs_a=None, coeffs_b=None):\n",
        "  # partial the dispatcher so we can pass the specific correction_type and coeffs\n",
        "  partial_apply = partial(\n",
        "      apply_correction_dispatcher,\n",
        "      correction_type=correction_type,\n",
        "      coeffs_l=coeffs_l,\n",
        "      coeffs_a=coeffs_a,\n",
        "      coeffs_b=coeffs_b\n",
        "  )\n",
        "\n",
        "  df[['correction_r0_l', 'correction_r0_a', 'correction_r0_b']] = df.apply(\n",
        "      lambda row: partial_apply(row, 'color_r0', radius = 0), axis=1\n",
        "  )\n",
        "  df[['correction_r2_l', 'correction_r2_a', 'correction_r2_b']] = df.apply(\n",
        "      lambda row: partial_apply(row, 'color_r2', radius = 2), axis=1\n",
        "  )\n",
        "  df[['correction_r4_l', 'correction_r4_a', 'correction_r4_b']] = df.apply(\n",
        "      lambda row: partial_apply(row, 'color_r4', radius = 4), axis=1\n",
        "  )\n",
        "\n",
        "print(\"Correction functions redefined for flexibility.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRstGpCBPhV7",
        "outputId": "4a6503f9-f88f-4375-985f-4c46782e2bb2"
      },
      "outputs": [],
      "source": [
        "correctRGB(df, correction_type='polynomial', coeffs_l=best_coeffs_l, coeffs_a=best_coeffs_a, coeffs_b=best_coeffs_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE in LAB space:\n",
            "  L Channel MSE: 26.68\n",
            "  A Channel MSE: 24.59\n",
            "  B Channel MSE: 26.37\n",
            "  Average MSE: 25.88\n"
          ]
        }
      ],
      "source": [
        "# Calculate MSE in LAB space\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse_l = mean_squared_error(df['gt__l'].values, df['correction_r4_l'].values)\n",
        "mse_a = mean_squared_error(df['gt__a'].values, df['correction_r4_a'].values)\n",
        "mse_b = mean_squared_error(df['gt__b'].values, df['correction_r4_b'].values)\n",
        "\n",
        "avg_mse_lab = (mse_l + mse_a + mse_b) / 3\n",
        "\n",
        "print(\"MSE in LAB space:\")\n",
        "print(f\"  L Channel MSE: {mse_l:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_lab:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e342334d",
        "outputId": "550bff12-4d09-4fbc-9866-09b77395cc51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed White Scaling MSE:\n",
            "  L Channel MSE: 36.71\n",
            "  A Channel MSE: 68.00\n",
            "  B Channel MSE: 300.42\n",
            "  Average MSE: 135.05\n",
            "\n",
            "Individually Optimized Polynomial Correction MSE:\n",
            "  L Channel MSE: 26.68\n",
            "  A Channel MSE: 24.59\n",
            "  B Channel MSE: 26.37\n",
            "  Average MSE: 25.88\n"
          ]
        }
      ],
      "source": [
        "# Calculate MSE for each channel in LAB\n",
        "mse_l_polynomial = mean_squared_error(df['gt__l'].values, df['correction_r4_l'].values)\n",
        "mse_a_polynomial = mean_squared_error(df['gt__a'].values, df['correction_r4_a'].values)\n",
        "mse_b_polynomial = mean_squared_error(df['gt__b'].values, df['correction_r4_b'].values)\n",
        "\n",
        "# Calculate average MSE\n",
        "avg_mse_polynomial = (mse_l_polynomial + mse_a_polynomial + mse_b_polynomial) / 3\n",
        "\n",
        "ref_l_white = 70.71\n",
        "ref_a_white = 0.39\n",
        "ref_b_white = 14.68\n",
        "\n",
        "# Apply the correction to the color_r4 values\n",
        "corrected_l_white_scaling, corrected_a_white_scaling, corrected_b_white_scaling = correctByFixedWhiteScaling(\n",
        "    ref_l_white, ref_a_white, ref_b_white,\n",
        "    df['color_r4_l'].values,\n",
        "    df['color_r4_a'].values,\n",
        "    df['color_r4_b'].values\n",
        ")\n",
        "\n",
        "# Calculate MSE for each channel in LAB\n",
        "mse_l_white_scaling = mean_squared_error(df['gt__l'].values, corrected_l_white_scaling)\n",
        "mse_a_white_scaling = mean_squared_error(df['gt__a'].values, corrected_a_white_scaling)\n",
        "mse_b_white_scaling = mean_squared_error(df['gt__b'].values, corrected_b_white_scaling)\n",
        "\n",
        "# Calculate average MSE\n",
        "avg_mse_white_scaling = (mse_l_white_scaling + mse_a_white_scaling + mse_b_white_scaling) / 3\n",
        "\n",
        "print(\"Fixed White Scaling MSE:\")\n",
        "print(f\"  L Channel MSE: {mse_l_white_scaling:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_white_scaling:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_white_scaling:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_white_scaling:.2f}\")\n",
        "\n",
        "\n",
        "print(\"\\nIndividually Optimized Polynomial Correction MSE:\")\n",
        "print(f\"  L Channel MSE: {mse_l_polynomial:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_polynomial:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_polynomial:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_polynomial:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os7oUAD_yuD5"
      },
      "source": [
        "## So, applying polynomials to correct L, A, B are better than using scaling, which is a linear term.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCfg-pc3ytlg"
      },
      "source": [
        "## Method 2: Using Matrix Correction:  \n",
        "## [correction_r2_l    correction_r2_a   correction_r2_b]^T\n",
        "## = [3 x 3 matrix] * [color_r2_l   color_r2_a   color_r2_b]^T\n",
        "## Our task: Learn 9 entries of the 3 x 3 matrix.\n",
        "## Conclusion: Compare with Fixed Scaling Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee0d25b8",
        "outputId": "ee215047-9c43-4c53-b65c-d9930c35e8b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix correction and optimization functions defined.\n"
          ]
        }
      ],
      "source": [
        "def _apply_matrix_transform(l, a, b, matrix):\n",
        "    \"\"\"\n",
        "    Applies a 3x3 transformation matrix to LAB values without clipping.\n",
        "    l, a, b can be scalars or NumPy arrays.\n",
        "    \"\"\"\n",
        "    # Ensure l, a, b are numpy arrays for consistent matrix multiplication\n",
        "    l_arr = np.atleast_1d(l)\n",
        "    a_arr = np.atleast_1d(a)\n",
        "    b_arr = np.atleast_1d(b)\n",
        "\n",
        "    # Stack LAB into a 3xN array (or 3x1 if scalars)\n",
        "    lab_stacked = np.vstack([l_arr, a_arr, b_arr])\n",
        "\n",
        "    # Perform matrix multiplication\n",
        "    corrected_lab_stacked = np.dot(matrix, lab_stacked)\n",
        "    # Return corrected L, A, B as separate arrays (or scalars if original inputs were)\n",
        "    if l_arr.ndim == 0:\n",
        "        return corrected_lab_stacked[0][0], corrected_lab_stacked[1][0], corrected_lab_stacked[2][0]\n",
        "    return corrected_lab_stacked[0], corrected_lab_stacked[1], corrected_lab_stacked[2]\n",
        "\n",
        "def correctByMatrix(l, a, b, matrix):\n",
        "    \"\"\"\n",
        "    Applies a 3x3 transformation matrix to LAB values and clips the results to [0, 255].\n",
        "    l, a, b can be scalars or NumPy arrays.\n",
        "    \"\"\"\n",
        "    corr_l, corr_a, corr_b = _apply_matrix_transform(l, a, b, matrix)\n",
        "    # Clip the resulting corrected L, A, B values to the range [0, 255]\n",
        "    corr_l_clipped = np.clip(corr_l, 0, 100)\n",
        "    corr_a_clipped = np.clip(corr_a, -128, 127)\n",
        "    corr_b_clipped = np.clip(corr_b, -128, 127)\n",
        "\n",
        "    return corr_l_clipped, corr_a_clipped, corr_b_clipped\n",
        "\n",
        "def calculateMatrixLoss(flat_matrix_elements, measured_l, measured_a, measured_b, gt_l, gt_a, gt_b):\n",
        "    \"\"\"\n",
        "    Loss function for optimizing a 3x3 transformation matrix.\n",
        "    \"\"\"\n",
        "    matrix = flat_matrix_elements.reshape(3, 3)\n",
        "    corr_l_unclipped, corr_a_unclipped, corr_b_unclipped = _apply_matrix_transform(\n",
        "        measured_l, measured_a, measured_b, matrix\n",
        "    )\n",
        "\n",
        "    # Calculate the Mean Squared Error (MSE) for each channel\n",
        "    mse_l = mean_squared_error(gt_l, corr_l_unclipped)\n",
        "    mse_a = mean_squared_error(gt_a, corr_a_unclipped)\n",
        "    mse_b = mean_squared_error(gt_b, corr_b_unclipped)\n",
        "\n",
        "    # Average MSE across channels\n",
        "    total_mse = (mse_l + mse_a + mse_b) / 3.0\n",
        "    # Add a boundary_penalty that penalizes values outside the range\n",
        "    boundary_penalty_l = np.mean((corr_l_unclipped < 0) | (corr_l_unclipped > 100)) * 1000\n",
        "    boundary_penalty_a = np.mean((corr_a_unclipped < -128) | (corr_a_unclipped > 127)) * 1000\n",
        "    boundary_penalty_b = np.mean((corr_b_unclipped < -128) | (corr_b_unclipped > 127)) * 1000\n",
        "    boundary_penalty = boundary_penalty_l + boundary_penalty_a + boundary_penalty_b\n",
        "\n",
        "    # Add a reg_penalty to penalize large matrix coefficients\n",
        "    reg_penalty = 0.001 * np.sum(np.abs(flat_matrix_elements))\n",
        "\n",
        "    # Return the sum of the MSE (average across channels), boundary penalty, and regularization penalty.\n",
        "    return total_mse + boundary_penalty + reg_penalty\n",
        "\n",
        "def get_identity_matrix_flat():\n",
        "    \"\"\"\n",
        "    Returns a 1D NumPy array representing a flattened 3x3 identity matrix.\n",
        "    This will serve as an initial guess for the optimization.\n",
        "    \"\"\"\n",
        "    return np.identity(3).flatten()\n",
        "\n",
        "print(\"Matrix correction and optimization functions defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72acbf3f",
        "outputId": "14935efa-ed25-437a-eac2-c70fffdb8079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted measured and ground truth LAB values.\n"
          ]
        }
      ],
      "source": [
        "measured_l = df['color_r4_l'].values\n",
        "measured_a = df['color_r4_a'].values\n",
        "measured_b = df['color_r4_b'].values\n",
        "\n",
        "gt_l = df['gt__l'].values\n",
        "gt_a = df['gt__a'].values\n",
        "gt_b = df['gt__b'].values\n",
        "\n",
        "print(\"Extracted measured and ground truth LAB values.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8e41782",
        "outputId": "dd0c32d0-0915-40b0-ba1a-3d98d3c62048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing 3x3 matrix...\n",
            "\n",
            "Optimization complete.\n",
            "Optimal 3x3 Transformation Matrix:\n",
            "[[ 1.33326447 -0.05409803  0.045444  ]\n",
            " [ 0.08549178  1.20895274 -0.13629488]\n",
            " [-0.0485153  -0.08019818  1.27326828]]\n"
          ]
        }
      ],
      "source": [
        "initial_guess = get_identity_matrix_flat()\n",
        "bounds = [(-5, 5)] * 9\n",
        "\n",
        "# Use partial to pass fixed arguments to the loss function\n",
        "loss_func_partial = partial(\n",
        "    calculateMatrixLoss,\n",
        "    measured_l=measured_l,\n",
        "    measured_a=measured_a,\n",
        "    measured_b=measured_b,\n",
        "    gt_l=gt_l,\n",
        "    gt_a=gt_a,\n",
        "    gt_b=gt_b\n",
        ")\n",
        "\n",
        "# Optimize using scipy.optimize.minimize\n",
        "print(\"Optimizing 3x3 matrix...\")\n",
        "result = minimize(\n",
        "    loss_func_partial,\n",
        "    initial_guess,\n",
        "    method='L-BFGS-B', # L-BFGS-B supports bounds\n",
        "    bounds=bounds,\n",
        "    options={'maxiter': 1000, 'ftol': 1e-8}\n",
        ")\n",
        "\n",
        "# Reshape the optimized 1D array of coefficients back into a 3x3 NumPy array\n",
        "optimal_matrix = result.x.reshape(3, 3)\n",
        "\n",
        "print(\"\\nOptimization complete.\")\n",
        "print(\"Optimal 3x3 Transformation Matrix:\")\n",
        "print(optimal_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d6a69b2",
        "outputId": "d81b56e2-4fce-41ea-fba8-55df5b9a597e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied matrix correction and stored results in new columns.\n"
          ]
        }
      ],
      "source": [
        "corrected_l_matrix, corrected_a_matrix, corrected_b_matrix = correctByMatrix(\n",
        "    df['color_r4_l'].values,\n",
        "    df['color_r4_a'].values,\n",
        "    df['color_r4_b'].values,\n",
        "    optimal_matrix\n",
        ")\n",
        "\n",
        "df['correction_r4_l_matrix'] = corrected_l_matrix\n",
        "df['correction_r4_a_matrix'] = corrected_a_matrix\n",
        "df['correction_r4_b_matrix'] = corrected_b_matrix\n",
        "\n",
        "print(\"Applied matrix correction and stored results in new columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24c68d19",
        "outputId": "947258bc-401b-42d6-bc25-450653709a93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Comparative Summary of Correction Methods ---\n",
            "\n",
            "1. Fixed White Scaling:\n",
            "  L Channel MSE: 36.71\n",
            "  A Channel MSE: 68.00\n",
            "  B Channel MSE: 300.42\n",
            "  Average MSE: 135.05\n",
            "\n",
            "2. Individually Optimized Polynomial Correction:\n",
            "  L Channel MSE: 26.68\n",
            "  A Channel MSE: 24.59\n",
            "  B Channel MSE: 26.37\n",
            "  Average MSE: 25.88\n",
            "\n",
            "3. Matrix Correction:\n",
            "  L Channel MSE: 28.69\n",
            "  A Channel MSE: 20.17\n",
            "  B Channel MSE: 37.54\n",
            "  Average MSE: 28.80\n"
          ]
        }
      ],
      "source": [
        "mse_l_matrix_correction = mean_squared_error(df['gt__l'].values, df['correction_r4_l_matrix'].values)\n",
        "mse_a_matrix_correction = mean_squared_error(df['gt__a'].values, df['correction_r4_a_matrix'].values)\n",
        "mse_b_matrix_correction = mean_squared_error(df['gt__b'].values, df['correction_r4_b_matrix'].values)\n",
        "\n",
        "avg_mse_matrix_correction = (mse_l_matrix_correction + mse_a_matrix_correction + mse_b_matrix_correction) / 3\n",
        "print(\"\\n--- Comparative Summary of Correction Methods ---\")\n",
        "\n",
        "print(\"\\n1. Fixed White Scaling:\")\n",
        "print(f\"  L Channel MSE: {mse_l_white_scaling:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_white_scaling:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_white_scaling:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_white_scaling:.2f}\")\n",
        "\n",
        "print(\"\\n2. Individually Optimized Polynomial Correction:\")\n",
        "print(f\"  L Channel MSE: {mse_l_polynomial:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_polynomial:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_polynomial:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_polynomial:.2f}\")\n",
        "\n",
        "print(\"\\n3. Matrix Correction:\")\n",
        "print(f\"  L Channel MSE: {mse_l_matrix_correction:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_matrix_correction:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_matrix_correction:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_matrix_correction:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BEHXmjW0KqQ"
      },
      "source": [
        "## Method 3: Multi-Input Correction\n",
        "We model the color correction as a polynomial mapping:\n",
        "`correction_r2 = f(color_r2, pitch, roll)`.\n",
        "\n",
        "The function `f` is parameterized using a low-order polynomial with carefully selected features:\n",
        "- **Linear color terms** (`L, A, B`) to capture the dominant color mapping.\n",
        "- **Second-order color terms** (`L², A², B², L·A, L·B, A·B`) to model mild nonlinear sensor responses.\n",
        "- **Pose-related terms** (`pitch, roll`) incorporated linearly to account for illumination changes due to camera orientation.\n",
        "\n",
        "Second-order color features are scaled for numerical stability, and stronger regularization is applied to their coefficients to prevent overfitting.\n",
        "\n",
        "## Objective\n",
        "Model parameters are learned by minimizing the mean squared error (MSE) between corrected and ground-truth colors, with additional regularization and boundary penalties.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_poly_features(measured_l, measured_a, measured_b, pitch, roll):\n",
        "    return np.vstack([\n",
        "        np.ones_like(measured_l),        # 1\n",
        "        measured_l,                      # L\n",
        "        measured_a,                      # A\n",
        "        measured_b,                      # B\n",
        "        (measured_l**2) / 100.0,                   # L^2\n",
        "        (measured_a**2) / 100.0,                   # A^2\n",
        "        (measured_b**2) / 100.0,                   # B^2\n",
        "        (measured_l * measured_a) / 100.0,         # L*A\n",
        "        (measured_l * measured_b) / 100.0,         # L*B\n",
        "        (measured_a * measured_b) / 100.0,         # A*B\n",
        "        pitch,                           # pitch\n",
        "        roll                             # roll\n",
        "    ]).T   # (N, 12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22ac79b6",
        "outputId": "e9dbedd7-8fbe-4931-fe07-3d5edab609e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "correctByMultiInputModel function defined.\n"
          ]
        }
      ],
      "source": [
        "def correctByMultiInputModel(measured_l, measured_a, measured_b, pitch, roll, coeffs):\n",
        "  # Ensure all inputs are NumPy arrays\n",
        "  measured_l = np.asarray(measured_l)\n",
        "  measured_a = np.asarray(measured_a)\n",
        "  measured_b = np.asarray(measured_b)\n",
        "  pitch = np.asarray(pitch)\n",
        "  roll = np.asarray(roll)\n",
        "  coeffs = np.asarray(coeffs)\n",
        "\n",
        "  # Each row corresponds to an output channel (l, a, b)\n",
        "  coeffs_matrix = coeffs.reshape(3, 12)\n",
        "\n",
        "  # Create an input_features matrix (N x 12)\n",
        "  input_features = build_poly_features(\n",
        "    measured_l, measured_a, measured_b, pitch, roll\n",
        "  )\n",
        "\n",
        "\n",
        "  # Perform matrix multiplication to calculate corrected LAB values\n",
        "  # coeffs_matrix (3x12) @ input_features.T (12xN) = corrected_lab_unclipped (3xN)\n",
        "  corrected_lab_unclipped = coeffs_matrix @ input_features.T\n",
        "\n",
        "  # Extract corrected L, A, B arrays\n",
        "  corrected_l_unclipped = corrected_lab_unclipped[0]\n",
        "  corrected_a_unclipped = corrected_lab_unclipped[1]\n",
        "  corrected_b_unclipped = corrected_lab_unclipped[2]\n",
        "\n",
        "  # Clip the corrected values to the range [0, 255] and convert to integer\n",
        "  corrected_l_clipped = np.clip(corrected_l_unclipped, 0, 100)\n",
        "  corrected_a_clipped = np.clip(corrected_a_unclipped, -128, 127)\n",
        "  corrected_b_clipped = np.clip(corrected_b_unclipped, -128, 127)\n",
        "\n",
        "  return corrected_l_clipped, corrected_a_clipped, corrected_b_clipped\n",
        "\n",
        "print(\"correctByMultiInputModel function defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1819c91",
        "outputId": "44cbfda8-d906-4682-f5f1-ad8b3a25593b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted measured LAB, sensor data (pitch, roll), and ground truth LAB values for multi-input model.\n"
          ]
        }
      ],
      "source": [
        "measured_l_multi = df['color_r4_l'].values\n",
        "measured_a_multi = df['color_r4_a'].values\n",
        "measured_b_multi = df['color_r4_b'].values\n",
        "\n",
        "pitch_multi = df['pitch'].values\n",
        "roll_multi = df['roll'].values\n",
        "\n",
        "gt_l_multi = df['gt__l'].values\n",
        "gt_a_multi = df['gt__a'].values\n",
        "gt_b_multi = df['gt__b'].values\n",
        "\n",
        "print(\"Extracted measured LAB, sensor data (pitch, roll), and ground truth LAB values for multi-input model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cdf8988",
        "outputId": "f1d586f6-d91e-4d2d-95c2-7d0a0e9daa51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`_apply_multi_input_model_unclipped` and `calculateMultiInputLoss` functions defined.\n"
          ]
        }
      ],
      "source": [
        "def _apply_multi_input_model_unclipped(measured_l, measured_a, measured_b, pitch, roll, coeffs):\n",
        "    # Ensure all inputs are NumPy arrays\n",
        "    measured_l = np.asarray(measured_l)\n",
        "    measured_a = np.asarray(measured_a)\n",
        "    measured_b = np.asarray(measured_b)\n",
        "    pitch = np.asarray(pitch)\n",
        "    roll = np.asarray(roll)\n",
        "    coeffs = np.asarray(coeffs)\n",
        "\n",
        "    # Reshape the 1D coeffs array into a 3x12 matrix\n",
        "    coeffs_matrix = coeffs.reshape(3, 12)\n",
        "\n",
        "    # Create an input_features matrix (N x 12)\n",
        "    input_features = build_poly_features(\n",
        "        measured_l, measured_a, measured_b, pitch, roll\n",
        "    )\n",
        "\n",
        "    # Perform matrix multiplication to calculate corrected LAB values\n",
        "    corrected_lab_unclipped = coeffs_matrix @ input_features.T\n",
        "\n",
        "    # Extract corrected L, A, B arrays\n",
        "    corrected_l_unclipped = corrected_lab_unclipped[0]\n",
        "    corrected_a_unclipped = corrected_lab_unclipped[1]\n",
        "    corrected_b_unclipped = corrected_lab_unclipped[2]\n",
        "\n",
        "    return corrected_l_unclipped, corrected_a_unclipped, corrected_b_unclipped\n",
        "\n",
        "def calculateMultiInputLoss(flat_coeffs, measured_l, measured_a, measured_b, pitch, roll, gt_l, gt_a, gt_b):\n",
        "    # Use the unclipped version of the model for loss calculation\n",
        "    corr_l_unclipped, corr_a_unclipped, corr_b_unclipped = _apply_multi_input_model_unclipped(\n",
        "        measured_l, measured_a, measured_b, pitch, roll, flat_coeffs\n",
        "    )\n",
        "\n",
        "    mse_l = mean_squared_error(gt_l, corr_l_unclipped)\n",
        "    mse_a = mean_squared_error(gt_a, corr_a_unclipped)\n",
        "    mse_b = mean_squared_error(gt_b, corr_b_unclipped)\n",
        "\n",
        "    total_mse = (mse_l + mse_a + mse_b) / 3.0  \n",
        "    # Implement boundary penalty\n",
        "    # Penalize values outside range\n",
        "    boundary_penalty = (\n",
        "        np.mean((corr_l_unclipped < 0) | (corr_l_unclipped > 100)) +\n",
        "        np.mean((corr_a_unclipped < -128) | (corr_a_unclipped > 127)) +\n",
        "        np.mean((corr_b_unclipped < -128) | (corr_b_unclipped > 127))\n",
        "    ) * 1000 # Scaling factor for boundary penalty\n",
        "\n",
        "    # Implement regularization penalty (L1 regularization on coefficients)\n",
        "    coeffs = flat_coeffs.reshape(3, 12)\n",
        "\n",
        "    reg_linear = 0.001 * np.sum(np.abs(coeffs[:, :4]))\n",
        "    reg_quad   = 0.01  * np.sum(np.abs(coeffs[:, 4:10]))\n",
        "    reg_pose   = 0.001 * np.sum(np.abs(coeffs[:, 10:]))\n",
        "\n",
        "    reg_penalty = reg_linear + reg_quad + reg_pose\n",
        "\n",
        "\n",
        "    # Return the total loss\n",
        "    return total_mse + boundary_penalty + reg_penalty\n",
        "\n",
        "print(\"`_apply_multi_input_model_unclipped` and `calculateMultiInputLoss` functions defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "026d8d1d",
        "outputId": "9eaac860-985e-4bb2-d795-465d9625d132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizing multi-input model coefficients...\n",
            "\n",
            "Optimization complete.\n",
            "Optimal Multi-Input Model Coefficients (3x12 matrix):\n",
            "[[ 0.13771492  1.38020982  0.10188925  0.00366497 -0.06148997  0.10205508\n",
            "  -0.06482548 -0.17379098  0.13849236 -0.58174073 -0.07576848 -0.00957819]\n",
            " [ 0.06710441  0.14621403  1.24110128 -0.06637957 -0.12405373  0.05323643\n",
            "  -0.06852408  0.14434637 -0.08887106 -0.34890025  0.01454931 -0.00894648]\n",
            " [-0.00314436  0.0379408  -0.21435289  1.25065719 -0.15669371 -0.50578181\n",
            "   0.07942171  0.19315327  0.1455912   0.47193145  0.01427585  0.017302  ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "from functools import partial\n",
        "\n",
        "initial_coeffs = np.zeros((3, 12))\n",
        "\n",
        "# L' ≈ L, A' ≈ A, B' ≈ B\n",
        "initial_coeffs[0, 1] = 1.0  # L\n",
        "initial_coeffs[1, 2] = 1.0  # A\n",
        "initial_coeffs[2, 3] = 1.0  # B\n",
        "\n",
        "initial_guess = initial_coeffs.flatten()\n",
        "\n",
        "\n",
        "# 2. Define bounds for the 36 coefficients\n",
        "bounds = [(-5.0, 5.0)] * 36\n",
        "\n",
        "# 3. Create a partial function for calculateMultiInputLoss\n",
        "loss_func_partial_multi_input = partial(\n",
        "    calculateMultiInputLoss,\n",
        "    measured_l=measured_l_multi,\n",
        "    measured_a=measured_a_multi,\n",
        "    measured_b=measured_b_multi,\n",
        "    pitch=pitch_multi,\n",
        "    roll=roll_multi,\n",
        "    gt_l=gt_l_multi,\n",
        "    gt_a=gt_a_multi,\n",
        "    gt_b=gt_b_multi\n",
        ")\n",
        "\n",
        "# 4. Use scipy.optimize.minimize\n",
        "print(\"Optimizing multi-input model coefficients...\")\n",
        "result_multi_input = minimize(\n",
        "    loss_func_partial_multi_input,\n",
        "    initial_guess,\n",
        "    method='L-BFGS-B',\n",
        "    bounds=bounds,\n",
        "    options={'maxiter': 1000, 'ftol': 1e-8}\n",
        ")\n",
        "\n",
        "# 5. Reshape the optimized 1D array of coefficients back into a 3x12 matrix\n",
        "optimal_multi_input_coeffs = result_multi_input.x.reshape(3, 12)\n",
        "\n",
        "# 6. Print the optimal_multi_input_coeffs matrix\n",
        "print(\"\\nOptimization complete.\")\n",
        "print(\"Optimal Multi-Input Model Coefficients (3x12 matrix):\")\n",
        "print(optimal_multi_input_coeffs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a57e1f90",
        "outputId": "af84e74f-f757-4ded-9c6c-14d29460d160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applied multi-input model correction and stored results in new columns: 'correction_r4_l_multi', 'correction_r4_a_multi', 'correction_r4_b_multi'.\n"
          ]
        }
      ],
      "source": [
        "corrected_l_multi, corrected_a_multi, corrected_b_multi = correctByMultiInputModel(\n",
        "    measured_l_multi,\n",
        "    measured_a_multi,\n",
        "    measured_b_multi,\n",
        "    pitch_multi,\n",
        "    roll_multi,\n",
        "    optimal_multi_input_coeffs.flatten() # Flatten the 3x12 matrix back to 1D for the function\n",
        ")\n",
        "\n",
        "df['correction_r4_l_multi'] = corrected_l_multi\n",
        "df['correction_r4_a_multi'] = corrected_a_multi\n",
        "df['correction_r4_b_multi'] = corrected_b_multi\n",
        "\n",
        "print(\"Applied multi-input model correction and stored results in new columns: 'correction_r4_l_multi', 'correction_r4_a_multi', 'correction_r4_b_multi'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multi-Input Model MSE:\n",
            "  L Channel MSE: 14.61\n",
            "  A Channel MSE: 15.61\n",
            "  B Channel MSE: 19.94\n",
            "  Average MSE: 16.72\n"
          ]
        }
      ],
      "source": [
        "mse_l_multi = mean_squared_error(df['gt__l'].values, df['correction_r4_l_multi'].values)\n",
        "mse_a_multi = mean_squared_error(df['gt__a'].values, df['correction_r4_a_multi'].values)\n",
        "mse_b_multi = mean_squared_error(df['gt__b'].values, df['correction_r4_b_multi'].values)\n",
        "\n",
        "avg_mse_multi = (mse_l_multi + mse_a_multi + mse_b_multi) / 3\n",
        "\n",
        "print(\"Multi-Input Model MSE:\")\n",
        "print(f\"  L Channel MSE: {mse_l_multi:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_multi:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_multi:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_multi:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Final Comparative Summary of All Correction Methods (LAB MSE) ---\n",
            "\n",
            "1. Fixed White Scaling:\n",
            "  L Channel MSE: 36.71\n",
            "  A Channel MSE: 68.00\n",
            "  B Channel MSE: 300.42\n",
            "  Average MSE: 135.05\n",
            "\n",
            "2. Individually Optimized Polynomial Correction:\n",
            "  L Channel MSE: 26.68\n",
            "  A Channel MSE: 24.59\n",
            "  B Channel MSE: 26.37\n",
            "  Average MSE: 25.88\n",
            "\n",
            "3. Matrix Correction:\n",
            "  L Channel MSE: 28.69\n",
            "  A Channel MSE: 20.17\n",
            "  B Channel MSE: 37.54\n",
            "  Average MSE: 28.80\n",
            "\n",
            "4. Multi-Input Model (with pitch & roll):\n",
            "  L Channel MSE: 14.61\n",
            "  A Channel MSE: 15.61\n",
            "  B Channel MSE: 19.94\n",
            "  Average MSE: 16.72\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Final Comparative Summary of All Correction Methods (LAB MSE) ---\")\n",
        "\n",
        "print(\"\\n1. Fixed White Scaling:\")\n",
        "print(f\"  L Channel MSE: {mse_l_white_scaling:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_white_scaling:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_white_scaling:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_white_scaling:.2f}\")\n",
        "\n",
        "print(\"\\n2. Individually Optimized Polynomial Correction:\")\n",
        "print(f\"  L Channel MSE: {mse_l_polynomial:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_polynomial:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_polynomial:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_polynomial:.2f}\")\n",
        "\n",
        "print(\"\\n3. Matrix Correction:\")\n",
        "print(f\"  L Channel MSE: {mse_l_matrix_correction:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_matrix_correction:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_matrix_correction:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_matrix_correction:.2f}\")\n",
        "\n",
        "print(\"\\n4. Multi-Input Model (with pitch & roll):\")\n",
        "print(f\"  L Channel MSE: {mse_l_multi:.2f}\")\n",
        "print(f\"  A Channel MSE: {mse_a_multi:.2f}\")\n",
        "print(f\"  B Channel MSE: {mse_b_multi:.2f}\")\n",
        "print(f\"  Average MSE: {avg_mse_multi:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
