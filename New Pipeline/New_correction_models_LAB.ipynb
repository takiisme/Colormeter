{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tpm7sS9nPcO7"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "# from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from functools import partial\n",
        "from matplotlib.colors import rgb_to_hsv\n",
        "from scipy import stats\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.optimize import minimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB48qSX0PheD",
        "outputId": "f16aaa73-c726-439e-edb7-f79c45bc6a55"
      },
      "outputs": [],
      "source": [
        "# Mount:\n",
        "# drive.mount('/content/drive', force_remount = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g9oElRwhPhbU"
      },
      "outputs": [],
      "source": [
        "# Read json file\n",
        "def readJsonData(JSON_FILE_PATH):\n",
        "  data = None\n",
        "  try:\n",
        "    with open(JSON_FILE_PATH, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    print(\"✅ JSON file loaded successfully.\")\n",
        "\n",
        "    metadata = data.get('metadata', {})\n",
        "    print(f\"\\n--- Session Metadata ---\")\n",
        "    for key, value in metadata.items():\n",
        "        print(f\"{key.ljust(20)}: {value}\")\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      print(f\"❌ ERROR: File not found at path: {JSON_FILE_PATH}\")\n",
        "      print(\"Please check the file path and ensure Google Drive is correctly mounted.\")\n",
        "  except json.JSONDecodeError:\n",
        "      print(\"❌ ERROR: Could not decode JSON. Ensure the file is valid.\")\n",
        "  return data\n",
        "\n",
        "# Preprocessing\n",
        "def preprocessData(data):\n",
        "  flat_data = []\n",
        "\n",
        "  # Extract metadata for easy merging later\n",
        "  session_metadata = data.get('metadata', {})\n",
        "  session_name = session_metadata.get('sessionName', 'Unknown Session')\n",
        "\n",
        "  # Iterate through each sample (color card)\n",
        "  for sample in data.get('data', []):\n",
        "      sample_number = sample.get('sampleNumber')\n",
        "\n",
        "      # Iterate through each measurement (1 to 10) within that sample\n",
        "      for capture_index, measurement in enumerate(sample.get('measurements', [])):\n",
        "\n",
        "          # Create a dictionary for the current row\n",
        "          row = {\n",
        "              'session_name': session_name,\n",
        "              'sample_number': sample_number,\n",
        "              'capture_index': capture_index, # 0 to 9\n",
        "              'lighting_condition': session_metadata.get('lightingCondition'),\n",
        "              'reflective_surface': session_metadata.get('useReflectiveSurface'),\n",
        "\n",
        "              # Sensor Data\n",
        "              'pitch': measurement['angles']['pitch'],\n",
        "              'roll': measurement['angles']['roll'],\n",
        "          }\n",
        "\n",
        "          # Extract Color Data (White and Color reticles, three radii each)\n",
        "\n",
        "          # White Reticle Captures\n",
        "          for radius in [0, 2, 4]:\n",
        "              capture_key = f'r{radius}'\n",
        "              color_data = measurement['white'].get(capture_key, {'r': 0, 'g': 0, 'b': 0})\n",
        "              row[f'white_r{radius}_R'] = color_data['r']\n",
        "              row[f'white_r{radius}_G'] = color_data['g']\n",
        "              row[f'white_r{radius}_B'] = color_data['b']\n",
        "\n",
        "          # Color Reticle Captures\n",
        "          for radius in [0, 2, 4]:\n",
        "              capture_key = f'r{radius}'\n",
        "              color_data = measurement['color'].get(capture_key, {'r': 0, 'g': 0, 'b': 0})\n",
        "              row[f'color_r{radius}_R'] = color_data['r']\n",
        "              row[f'color_r{radius}_G'] = color_data['g']\n",
        "              row[f'color_r{radius}_B'] = color_data['b']\n",
        "\n",
        "          flat_data.append(row)\n",
        "\n",
        "  # Convert the list of dictionaries to a Pandas DataFrame\n",
        "  df = pd.DataFrame(flat_data)\n",
        "\n",
        "  print(f\"\\n✅ Data flattened into DataFrame with {len(df)} rows (Total captures: 24 samples * 10 captures = 240 rows).\")\n",
        "  return df\n",
        "\n",
        "# ## 3. Initial Review and Visualization\n",
        "\n",
        "# Display the first few rows and the column types for verification.\n",
        "def displayDataFrameInfo(df):\n",
        "  print(\"\\n--- DataFrame Head (First 5 Rows) ---\")\n",
        "  print(df.head())\n",
        "\n",
        "  print(\"\\n--- DataFrame Information ---\")\n",
        "  print(df.info())\n",
        "\n",
        "  # ### 3.1 Check Sensor Variability\n",
        "\n",
        "  # This checks the pitch/roll stability across all 240 measurements.\n",
        "  print(\"\\n--- Sensor Angle Statistics ---\")\n",
        "  print(df[['pitch', 'roll']].describe())\n",
        "\n",
        "def merge_datasets_for_model(dfs):\n",
        "    \"\"\"\n",
        "    Vertically concatenate multiple datasets.\n",
        "    All rows are kept. Column names must be consistent.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dfs : list of pd.DataFrame\n",
        "        List of datasets with identical column structure\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Combined dataset\n",
        "    \"\"\"\n",
        "    merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
        "    return merged_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PcqcwYAwPhYk"
      },
      "outputs": [],
      "source": [
        "def combineGroundTruth(df):\n",
        "  ground_truth_data = [\n",
        "      {'sample_number': 1,  'label': 'Dark Skin',      'gt__R': 115, 'gt__G': 82,  'gt__B': 69},\n",
        "      {'sample_number': 2,  'label': 'Light Skin',     'gt__R': 204, 'gt__G': 161, 'gt__B': 141},\n",
        "      {'sample_number': 3,  'label': 'Blue Sky',       'gt__R': 101, 'gt__G': 134, 'gt__B': 179},\n",
        "      {'sample_number': 4,  'label': 'Foliage',        'gt__R': 89,  'gt__G': 109, 'gt__B': 61},\n",
        "      {'sample_number': 5,  'label': 'Blue Flower',    'gt__R': 141, 'gt__G': 137, 'gt__B': 194},\n",
        "      {'sample_number': 6,  'label': 'Bluish Green',   'gt__R': 132, 'gt__G': 228, 'gt__B': 208},\n",
        "      {'sample_number': 7,  'label': 'Orange',         'gt__R': 249, 'gt__G': 118, 'gt__B': 35},\n",
        "      {'sample_number': 8,  'label': 'Purplish Blue',  'gt__R': 80,  'gt__G': 91,  'gt__B': 182},\n",
        "      {'sample_number': 9,  'label': 'Moderate Red',   'gt__R': 222, 'gt__G': 91,  'gt__B': 125},\n",
        "      {'sample_number': 10, 'label': 'Purple',         'gt__R': 91,  'gt__G': 63,  'gt__B': 123},\n",
        "      {'sample_number': 11, 'label': 'Yellow Green',   'gt__R': 173, 'gt__G': 232, 'gt__B': 91},\n",
        "      {'sample_number': 12, 'label': 'Orange Yellow',  'gt__R': 255, 'gt__G': 164, 'gt__B': 26},\n",
        "      {'sample_number': 13, 'label': 'Blue',           'gt__R': 44,  'gt__G': 56,  'gt__B': 142},\n",
        "      {'sample_number': 14, 'label': 'Green',          'gt__R': 74,  'gt__G': 148, 'gt__B': 81},\n",
        "      {'sample_number': 15, 'label': 'Red',            'gt__R': 179, 'gt__G': 42,  'gt__B': 50},\n",
        "      {'sample_number': 16, 'label': 'Yellow',         'gt__R': 250, 'gt__G': 226, 'gt__B': 21},\n",
        "      {'sample_number': 17, 'label': 'Magenta',        'gt__R': 191, 'gt__G': 81,  'gt__B': 160},\n",
        "      {'sample_number': 18, 'label': 'Cyan',           'gt__R': 6,   'gt__G': 142, 'gt__B': 172},\n",
        "      {'sample_number': 19, 'label': 'White',          'gt__R': 252, 'gt__G': 252, 'gt__B': 252},\n",
        "      {'sample_number': 20, 'label': 'Neutral 8',      'gt__R': 230, 'gt__G': 230, 'gt__B': 230},\n",
        "      {'sample_number': 21, 'label': 'Neutral 6.5',    'gt__R': 200, 'gt__G': 200, 'gt__B': 200},\n",
        "      {'sample_number': 22, 'label': 'Neutral 5',      'gt__R': 143, 'gt__G': 143, 'gt__B': 142},\n",
        "      {'sample_number': 23, 'label': 'Neutral 3.5',    'gt__R': 100, 'gt__G': 100, 'gt__B': 100},\n",
        "      {'sample_number': 24, 'label': 'Black',          'gt__R': 50,  'gt__G': 50,  'gt__B': 50},\n",
        "  ]\n",
        "  df_gt = pd.DataFrame(ground_truth_data)\n",
        "  df = pd.merge(df, df_gt, on='sample_number', how='outer')\n",
        "\n",
        "  return df, df_gt\n",
        "\n",
        "def generateFinalDataFrame(df_with_gt_columns):\n",
        "  # Calculate average color and corrected color values per sample_number\n",
        "  avg_cols_to_compute = [\n",
        "      'color_r0_R', 'color_r0_G', 'color_r0_B',\n",
        "      'correction_r0_R', 'correction_r0_G', 'correction_r0_B',\n",
        "      'color_r2_R', 'color_r2_G', 'color_r2_B',\n",
        "      'correction_r2_R', 'correction_r2_G', 'correction_r2_B',\n",
        "      'color_r4_R', 'color_r4_G', 'color_r4_B',\n",
        "      'correction_r4_R', 'correction_r4_G', 'correction_r4_B'\n",
        "  ]\n",
        "  df_avg = df_with_gt_columns.groupby('sample_number')[avg_cols_to_compute].mean().reset_index()\n",
        "\n",
        "  # Rename columns to 'avg_...' to clearly distinguish them\n",
        "  new_avg_columns_map = {col: 'avg_' + col for col in avg_cols_to_compute}\n",
        "  df_avg = df_avg.rename(columns=new_avg_columns_map)\n",
        "\n",
        "  # Merge the df (which now has ground truth) with the averaged color data\n",
        "  df_final_comparison = pd.merge(df_with_gt_columns, df_avg, on='sample_number', how='left')\n",
        "\n",
        "  return df_final_comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM9XoJWJQCzU",
        "outputId": "0e556d3e-e507-4feb-f5d8-caa1dc30fbe7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ JSON file loaded successfully.\n",
            "\n",
            "--- Session Metadata ---\n",
            "sessionName         : baisu1\n",
            "lightingCondition   : 0\n",
            "useReflectiveSurface: False\n",
            "dateTime            : 2025-11-19T15:01:46.558942\n",
            "\n",
            "✅ Data flattened into DataFrame with 240 rows (Total captures: 24 samples * 10 captures = 240 rows).\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing testing data\n",
        "jsonFilePath = '../Data/Baisu1.json'\n",
        "data = readJsonData(jsonFilePath)\n",
        "df = preprocessData(data)\n",
        "df, _ = combineGroundTruth(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0RXNyH8y_uw"
      },
      "source": [
        "## Method: Using Polynomial Correction:  \n",
        "\n",
        "The correction method uses three-channel polynomial regression:\n",
        "\n",
        "$$\n",
        "\\hat{L} = f_L(L_m, A_m, B_m), \\quad\n",
        "\\hat{A} = f_A(L_m, A_m, B_m), \\quad\n",
        "\\hat{B} = f_B(L_m, A_m, B_m)\n",
        "$$\n",
        "\n",
        "where $L_m, A_m, B_m$ are the measured HSV values, and $f_L, f_A, f_B$ are polynomial functions.  \n",
        "\n",
        "In matrix form:\n",
        "\n",
        "$$\n",
        "\\hat{C} = X \\cdot \\Theta, \\quad\n",
        "X = [1, L_m^1, \\dots, L_m^d, \\; A_m^1, \\dots, A_m^d, \\; B_m^1, \\dots, B_m^d]\n",
        "$$\n",
        "\n",
        "where $d$ is the polynomial degree, $\\Theta$ is the coefficient vector, and $\\hat{C} = [\\hat{L}, \\hat{A}, \\hat{B}]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPO80CP0P0Yc",
        "outputId": "981891da-bb8b-421d-e731-cd534601fcd5"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Design matrix: polynomial terms\n",
        "# ============================================================\n",
        "def build_design_matrix(measured_h, measured_s, measured_v, degree):\n",
        "    \"\"\"\n",
        "    Build design matrix using all HSV channels.\n",
        "    Each channel's polynomial terms are included.\n",
        "    \n",
        "    Returns:\n",
        "        X: (N, 3*degree + 1)\n",
        "           [1, l^1..l^degree, a^1..a^degree, b^1..b^degree]\n",
        "    \"\"\"\n",
        "    N = len(measured_h)\n",
        "    \n",
        "    bias = np.ones((N, 1))\n",
        "    # polynomial terms for each channel\n",
        "    X_l = np.vstack([measured_h**k for k in range(1, degree+1)]).T\n",
        "    X_a = np.vstack([measured_s**k for k in range(1, degree+1)]).T\n",
        "    X_b = np.vstack([measured_v**k for k in range(1, degree+1)]).T\n",
        "    # concatenate all\n",
        "    X = np.hstack([bias, X_l, X_a, X_b])\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Loss function (MSE + boundary penalty + L2 regularization)\n",
        "# ============================================================\n",
        "def regression_loss(theta, X, y, reg_lambda=1e-2, lower_bound=0.0, upper_bound=1.0):\n",
        "    \"\"\"\n",
        "    theta: regression coefficients\n",
        "    X: design matrix\n",
        "    y: ground truth\n",
        "    \"\"\"\n",
        "    y_pred = X @ theta\n",
        "    mse = mean_squared_error(y, y_pred)\n",
        "    # Penalize predictions outside valid intensity range\n",
        "\n",
        "    penalty_low = np.mean(np.maximum(lower_bound - y_pred, 0.0)**2)\n",
        "    penalty_high = np.mean(np.maximum(y_pred - upper_bound, 0.0)**2)\n",
        "\n",
        "    boundary_penalty = penalty_low + penalty_high\n",
        "    reg = reg_lambda * np.sum(theta**2)\n",
        "    return mse + reg + boundary_penalty\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Optimize one color channel\n",
        "# ============================================================\n",
        "def fit_single_channel(measured_l, measured_a, measured_b, gt, degree, channel):\n",
        "    \"\"\"\n",
        "    Fit polynomial model for one LAB channel using all channels.\n",
        "    \"\"\"\n",
        "    X = build_design_matrix(measured_l, measured_a, measured_b, degree)\n",
        "    # initial guess\n",
        "    theta0 = np.zeros(X.shape[1])\n",
        "    # roughly identity mapping for self channel\n",
        "    theta0[1] = 1.0\n",
        "\n",
        "    # Set bounds based on channel\n",
        "    if channel == 'l':\n",
        "        lower_bound = 0.0\n",
        "        upper_bound = 100.0\n",
        "    elif channel in ['a', 'b']:\n",
        "        lower_bound = -128.0\n",
        "        upper_bound = 127.0\n",
        "\n",
        "    result = minimize(\n",
        "        regression_loss,\n",
        "        theta0,\n",
        "        args=(X, gt, 1e-2, lower_bound, upper_bound),\n",
        "        method=\"L-BFGS-B\"\n",
        "    )\n",
        "    return {\n",
        "        \"theta\": result.x,\n",
        "        \"success\": result.success,\n",
        "        \"final_mse\": mean_squared_error(gt, X @ result.x)\n",
        "    }\n",
        "\n",
        "def fit_hsv_polynomial(\n",
        "    df,\n",
        "    max_degree=5,\n",
        "    meas_prefix=\"color_r4_\",\n",
        "    gt_prefix=\"gt__\"\n",
        "):\n",
        "    \"\"\"\n",
        "    Fit polynomial regression for LAB channels using all channels as input.\n",
        "    \"\"\"\n",
        "    measured_l = df[f\"{meas_prefix}l\"].values\n",
        "    measured_a = df[f\"{meas_prefix}a\"].values\n",
        "    measured_b = df[f\"{meas_prefix}b\"].values\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for ch, gt_col in zip([\"l\", \"a\", \"b\"], [\"gt__l\", \"gt__a\", \"gt__b\"]):\n",
        "        gt = df[gt_col].values\n",
        "        best_mse = np.inf\n",
        "        best_result = None\n",
        "        best_degree = None\n",
        "        all_results = {}\n",
        "\n",
        "        for degree in range(1, max_degree+1):\n",
        "            res = fit_single_channel(measured_l, measured_a, measured_b, gt, degree, ch)\n",
        "            all_results[degree] = res\n",
        "\n",
        "            print(\"degree\",degree,\"mse\",res[\"final_mse\"])\n",
        "            if res[\"success\"] and res[\"final_mse\"] < best_mse:\n",
        "                best_mse = res[\"final_mse\"]\n",
        "                best_result = res\n",
        "                best_degree = degree\n",
        "\n",
        "        results[ch] = {\n",
        "            \"best_degree\": best_degree,\n",
        "            \"theta\": best_result[\"theta\"],\n",
        "            \"final_mse\": best_mse,\n",
        "            \"success\": best_result[\"success\"],\n",
        "            \"all_results\": all_results\n",
        "        }\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THg03tmuP0Tc",
        "outputId": "a9aabd4c-0c9d-4c7c-db34-d3e45d66d9f9"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Polynomial correction (all channels)\n",
        "# ============================================================\n",
        "def correctByPolynomial(meas_l, meas_a, meas_b, coeffs):\n",
        "    \"\"\"\n",
        "    Correct LAB values using a polynomial model.\n",
        "    coeffs: array of shape (num_features,) learned from training\n",
        "    \"\"\"\n",
        "    coeffs = np.asarray(coeffs, dtype=np.float64)\n",
        "\n",
        "    # ensure all inputs are arrays\n",
        "    meas_l = np.atleast_1d(np.asarray(meas_l, dtype=np.float64))\n",
        "    meas_a = np.atleast_1d(np.asarray(meas_a, dtype=np.float64))\n",
        "    meas_b = np.atleast_1d(np.asarray(meas_b, dtype=np.float64))\n",
        "\n",
        "    # automatically infer degree from coeffs\n",
        "    # number of features per channel = degree\n",
        "    # total columns = 3*degree + 1\n",
        "    num_features = len(coeffs)\n",
        "    degree = (num_features - 1) // 3\n",
        "    if degree < 0:\n",
        "        raise ValueError(f\"Invalid number of coefficients: {len(coeffs)}\")\n",
        "\n",
        "    # build design matrix\n",
        "    N = len(meas_l)\n",
        "    bias = np.ones((N, 1))\n",
        "    X_l = np.vstack([meas_l**k for k in range(1, degree+1)]).T\n",
        "    X_a = np.vstack([meas_a**k for k in range(1, degree+1)]).T\n",
        "    X_b = np.vstack([meas_b**k for k in range(1, degree+1)]).T\n",
        "    X = np.hstack([bias, X_l, X_a, X_b])  # shape (N, 3*degree + 1)\n",
        "\n",
        "    corr = X @ coeffs\n",
        "\n",
        "    # return scalar if input was scalar\n",
        "    return corr[0] if corr.size == 1 else corr\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Dispatcher for row-wise correction\n",
        "# ============================================================\n",
        "from functools import partial\n",
        "\n",
        "def apply_correction_dispatcher(row, color_prefix, radius,\n",
        "                                correction_type,\n",
        "                                coeffs_L=None, coeffs_A=None, coeffs_B=None):\n",
        "    meas_l = row[f'{color_prefix}_l']\n",
        "    meas_a = row[f'{color_prefix}_a']\n",
        "    meas_b = row[f'{color_prefix}_b']\n",
        "\n",
        "    # Polynomial correction automatically matches coeffs\n",
        "    corr_l = correctByPolynomial(meas_l, meas_a, meas_b, coeffs_L)\n",
        "    corr_a = correctByPolynomial(meas_l, meas_a, meas_b, coeffs_A)\n",
        "    corr_b = correctByPolynomial(meas_l, meas_a, meas_b, coeffs_B)\n",
        "\n",
        "    # Clip and convert to integer\n",
        "    corr_l = np.clip(corr_l, 0, 100)\n",
        "    corr_a = np.clip(corr_a, -128, 127)\n",
        "    corr_b = np.clip(corr_b, -128, 127)\n",
        "\n",
        "    return pd.Series([corr_l, corr_a, corr_b])\n",
        "# ============================================================\n",
        "# Main function to apply corrections to DataFrame\n",
        "# ============================================================\n",
        "def correctLAB(df, correction_type, coeffs_L=None, coeffs_A=None, coeffs_B=None):\n",
        "    \"\"\"\n",
        "    Apply correction to all r0, r2, r4 columns in DataFrame.\n",
        "    Supports white_scaling or polynomial (all channels)\n",
        "    \"\"\"\n",
        "\n",
        "    partial_apply = partial(\n",
        "        apply_correction_dispatcher,\n",
        "        correction_type=correction_type,\n",
        "        coeffs_L=coeffs_L,\n",
        "        coeffs_A=coeffs_A,\n",
        "        coeffs_B=coeffs_B\n",
        "    )\n",
        "\n",
        "    for radius in [0, 2, 4]:\n",
        "        color_prefix = f'color_r{radius}'\n",
        "        df[[f'correction_r{radius}_l', f'correction_r{radius}_a', f'correction_r{radius}_b']] = df.apply(\n",
        "            lambda row: partial_apply(row, color_prefix, radius), axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRstGpCBPhV7",
        "outputId": "4a6503f9-f88f-4375-985f-4c46782e2bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "degree 1 mse 24.33579056147413\n",
            "degree 2 mse 22.808989239476457\n",
            "degree 3 mse 27.395389259957973\n",
            "degree 4 mse 36.1809427142855\n",
            "degree 5 mse 150.92315486533462\n",
            "degree 1 mse 18.243319612087017\n",
            "degree 2 mse 17.83093556486562\n",
            "degree 3 mse 17.082075022707045\n",
            "degree 4 mse 148.38553010735134\n",
            "degree 5 mse 979.5973049179613\n",
            "degree 1 mse 35.70144326701417\n",
            "degree 2 mse 24.000578546527176\n",
            "degree 3 mse 33.312280480041\n",
            "degree 4 mse 208.7997831564345\n",
            "degree 5 mse 1354.3960543436806\n",
            "\n",
            "--- DataFrame Head (First 5 Rows) ---\n",
            "  session_name  sample_number  capture_index  lighting_condition  \\\n",
            "0       baisu1              1              0                   0   \n",
            "1       baisu1              1              1                   0   \n",
            "2       baisu1              1              2                   0   \n",
            "3       baisu1              1              3                   0   \n",
            "4       baisu1              1              4                   0   \n",
            "\n",
            "   reflective_surface      pitch      roll  white_r0_R  white_r0_G  \\\n",
            "0               False -29.693001  1.293356         171         175   \n",
            "1               False  -8.531617  0.876035         176         180   \n",
            "2               False   5.271871  1.447423         179         182   \n",
            "3               False  18.241475  1.187735         180         183   \n",
            "4               False  30.369560  1.290507         181         184   \n",
            "\n",
            "   white_r0_B  ...  color_r0_V  color_r2_H  color_r2_S  color_r2_V  \\\n",
            "0         178  ...    0.337255    0.050000    0.465116    0.337255   \n",
            "1         183  ...    0.349020    0.052846    0.460674    0.349020   \n",
            "2         187  ...    0.333333    0.055556    0.428571    0.329412   \n",
            "3         188  ...    0.360784    0.055556    0.391304    0.360784   \n",
            "4         189  ...    0.380392    0.062500    0.329897    0.380392   \n",
            "\n",
            "   color_r4_H  color_r4_S  color_r4_V     gt__H  gt__S    gt__V  \n",
            "0    0.050000    0.465116    0.337255  0.047101    0.4  0.45098  \n",
            "1    0.052846    0.460674    0.349020  0.047101    0.4  0.45098  \n",
            "2    0.055556    0.428571    0.329412  0.047101    0.4  0.45098  \n",
            "3    0.055556    0.391304    0.360784  0.047101    0.4  0.45098  \n",
            "4    0.062500    0.329897    0.380392  0.047101    0.4  0.45098  \n",
            "\n",
            "[5 rows x 71 columns]\n",
            "\n",
            "--- DataFrame Information ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 240 entries, 0 to 239\n",
            "Data columns (total 71 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   session_name        240 non-null    object \n",
            " 1   sample_number       240 non-null    int64  \n",
            " 2   capture_index       240 non-null    int64  \n",
            " 3   lighting_condition  240 non-null    int64  \n",
            " 4   reflective_surface  240 non-null    bool   \n",
            " 5   pitch               240 non-null    float64\n",
            " 6   roll                240 non-null    float64\n",
            " 7   white_r0_R          240 non-null    int64  \n",
            " 8   white_r0_G          240 non-null    int64  \n",
            " 9   white_r0_B          240 non-null    int64  \n",
            " 10  white_r2_R          240 non-null    int64  \n",
            " 11  white_r2_G          240 non-null    int64  \n",
            " 12  white_r2_B          240 non-null    int64  \n",
            " 13  white_r4_R          240 non-null    int64  \n",
            " 14  white_r4_G          240 non-null    int64  \n",
            " 15  white_r4_B          240 non-null    int64  \n",
            " 16  color_r0_R          240 non-null    int64  \n",
            " 17  color_r0_G          240 non-null    int64  \n",
            " 18  color_r0_B          240 non-null    int64  \n",
            " 19  color_r2_R          240 non-null    int64  \n",
            " 20  color_r2_G          240 non-null    int64  \n",
            " 21  color_r2_B          240 non-null    int64  \n",
            " 22  color_r4_R          240 non-null    int64  \n",
            " 23  color_r4_G          240 non-null    int64  \n",
            " 24  color_r4_B          240 non-null    int64  \n",
            " 25  label               240 non-null    object \n",
            " 26  gt__R               240 non-null    int64  \n",
            " 27  gt__G               240 non-null    int64  \n",
            " 28  gt__B               240 non-null    int64  \n",
            " 29  gt__l               240 non-null    float64\n",
            " 30  gt__a               240 non-null    float64\n",
            " 31  gt__b               240 non-null    float64\n",
            " 32  color_r0_l          240 non-null    float64\n",
            " 33  color_r0_a          240 non-null    float64\n",
            " 34  color_r0_b          240 non-null    float64\n",
            " 35  color_r2_l          240 non-null    float64\n",
            " 36  color_r2_a          240 non-null    float64\n",
            " 37  color_r2_b          240 non-null    float64\n",
            " 38  color_r4_l          240 non-null    float64\n",
            " 39  color_r4_a          240 non-null    float64\n",
            " 40  color_r4_b          240 non-null    float64\n",
            " 41  correction_r0_l     240 non-null    float64\n",
            " 42  correction_r0_a     240 non-null    float64\n",
            " 43  correction_r0_b     240 non-null    float64\n",
            " 44  correction_r2_l     240 non-null    float64\n",
            " 45  correction_r2_a     240 non-null    float64\n",
            " 46  correction_r2_b     240 non-null    float64\n",
            " 47  correction_r4_l     240 non-null    float64\n",
            " 48  correction_r4_a     240 non-null    float64\n",
            " 49  correction_r4_b     240 non-null    float64\n",
            " 50  white_r0_H          240 non-null    float64\n",
            " 51  white_r0_S          240 non-null    float64\n",
            " 52  white_r0_V          240 non-null    float64\n",
            " 53  white_r2_H          240 non-null    float64\n",
            " 54  white_r2_S          240 non-null    float64\n",
            " 55  white_r2_V          240 non-null    float64\n",
            " 56  white_r4_H          240 non-null    float64\n",
            " 57  white_r4_S          240 non-null    float64\n",
            " 58  white_r4_V          240 non-null    float64\n",
            " 59  color_r0_H          240 non-null    float64\n",
            " 60  color_r0_S          240 non-null    float64\n",
            " 61  color_r0_V          240 non-null    float64\n",
            " 62  color_r2_H          240 non-null    float64\n",
            " 63  color_r2_S          240 non-null    float64\n",
            " 64  color_r2_V          240 non-null    float64\n",
            " 65  color_r4_H          240 non-null    float64\n",
            " 66  color_r4_S          240 non-null    float64\n",
            " 67  color_r4_V          240 non-null    float64\n",
            " 68  gt__H               240 non-null    float64\n",
            " 69  gt__S               240 non-null    float64\n",
            " 70  gt__V               240 non-null    float64\n",
            "dtypes: bool(1), float64(44), int64(24), object(2)\n",
            "memory usage: 131.6+ KB\n",
            "None\n",
            "\n",
            "--- Sensor Angle Statistics ---\n",
            "            pitch        roll\n",
            "count  240.000000  240.000000\n",
            "mean     4.455454    3.162351\n",
            "std     16.403343   17.747671\n",
            "min    -32.879422  -34.056684\n",
            "25%      1.408157   -0.132885\n",
            "50%      5.156607    1.786664\n",
            "75%      8.215095    4.700334\n",
            "max     39.911517   41.455027\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('..')\n",
        "import color_conversion\n",
        "color_conversion.convert_rgb_cols(df, prefix='gt__', to='lab')\n",
        "color_conversion.convert_rgb_cols(df, prefix='color_r0_', to='lab')\n",
        "color_conversion.convert_rgb_cols(df, prefix='color_r2_', to='lab')\n",
        "color_conversion.convert_rgb_cols(df, prefix='color_r4_', to='lab')\n",
        "best_result = fit_hsv_polynomial(df)\n",
        "\n",
        "\n",
        "best_coeffs_L = best_result[\"l\"][\"theta\"]\n",
        "best_coeffs_A = best_result[\"a\"][\"theta\"]\n",
        "best_coeffs_B = best_result[\"b\"][\"theta\"]\n",
        "\n",
        "df = correctLAB(\n",
        "    df,\n",
        "    correction_type='polynomial',\n",
        "    coeffs_L=best_coeffs_L,\n",
        "    coeffs_A=best_coeffs_A,\n",
        "    coeffs_B=best_coeffs_B\n",
        ")\n",
        "def rgb_to_hsv_wrapper(r, g, b):\n",
        "    # Normalize RGB values to [0, 1]\n",
        "    rgb_normalized = np.array([r, g, b]) / 255.0\n",
        "    h, s, v = rgb_to_hsv(rgb_normalized)\n",
        "    return pd.Series([h, s, v])\n",
        "\n",
        "# Convert original RGB values to HSV and add to DataFrame\n",
        "rgb_column_sets = [\n",
        "    ('white', 'r0'), ('white', 'r2'), ('white', 'r4'),\n",
        "    ('color', 'r0'), ('color', 'r2'), ('color', 'r4'),\n",
        "    ('gt', '') # This entry needs to be fixed to match the new gt__R naming\n",
        "]\n",
        "\n",
        "for prefix, radius in rgb_column_sets:\n",
        "    # Special handling for ground truth to match the double underscore naming\n",
        "    if prefix == 'gt':\n",
        "        r_col, g_col, b_col = 'gt__R', 'gt__G', 'gt__B'\n",
        "        h_col, s_col, v_col = 'gt__H', 'gt__S', 'gt__V'\n",
        "    else:\n",
        "        r_col, g_col, b_col = f'{prefix}_{radius}_R', f'{prefix}_{radius}_G', f'{prefix}_{radius}_B'\n",
        "        h_col, s_col, v_col = f'{prefix}_{radius}_H', f'{prefix}_{radius}_S', f'{prefix}_{radius}_V'\n",
        "\n",
        "    df[[h_col, s_col, v_col]] = df.apply(\n",
        "        lambda row: rgb_to_hsv_wrapper(row[r_col], row[g_col], row[b_col]),\n",
        "        axis=1, result_type='expand'\n",
        "    )\n",
        "displayDataFrameInfo(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "New Polynomial correction MSE (r4):\n",
            "  L channel MSE: 22.79\n",
            "  A channel MSE: 17.08\n",
            "  B channel MSE: 24.00\n",
            "  Average MSE : 21.29\n"
          ]
        }
      ],
      "source": [
        "mse_l = mean_squared_error(df['gt__l'], df['correction_r4_l'])\n",
        "mse_a = mean_squared_error(df['gt__a'], df['correction_r4_a'])\n",
        "mse_b = mean_squared_error(df['gt__b'], df['correction_r4_b'])\n",
        "avg_mse = (mse_l + mse_a + mse_b) / 3.0\n",
        "print(\"\\nNew Polynomial correction MSE (r4):\")\n",
        "print(f\"  L channel MSE: {mse_l:.2f}\")\n",
        "print(f\"  A channel MSE: {mse_a:.2f}\")\n",
        "print(f\"  B channel MSE: {mse_b:.2f}\")\n",
        "print(f\"  Average MSE : {avg_mse:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
