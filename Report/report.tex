%%%%%%%% DATA LITERACY 2025 LATEX PROJECT TEMPLATE FILE %%%%%%%%%%%%%%%%%
%%% Based on the 2025 ICML template, available at https://icml.cc/Conferences/2025/AuthorInstructions %%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

\usepackage{tikz}
% Corporate Design of the University of Tübingen
% Primary Colors
\definecolor{TUred}{RGB}{165,30,55}
\definecolor{TUgold}{RGB}{180,160,105}
\definecolor{TUdark}{RGB}{50,65,75}
\definecolor{TUgray}{RGB}{175,179,183}

% Secondary Colors
\definecolor{TUdarkblue}{RGB}{65,90,140}
\definecolor{TUblue}{RGB}{0,105,170}
\definecolor{TUlightblue}{RGB}{80,170,200}
\definecolor{TUlightgreen}{RGB}{130,185,160}
\definecolor{TUgreen}{RGB}{125,165,75}
\definecolor{TUdarkgreen}{RGB}{50,110,30}
\definecolor{TUocre}{RGB}{200,80,60}
\definecolor{TUviolet}{RGB}{175,110,150}
\definecolor{TUmauve}{RGB}{180,160,150}
\definecolor{TUbeige}{RGB}{215,180,105}
\definecolor{TUorange}{RGB}{210,150,0}
\definecolor{TUbrown}{RGB}{145,105,70}

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

\usepackage[accepted]{icml2025}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}

\usepackage{enumitem}
% \setlist{noitemsep}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Project Report Template for Data Literacy 2025}

\begin{document}

\twocolumn[
\icmltitle{My Data Literacy Project\\ (Replace this with your Project Title)}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
% Alphabetic order, equal contribution anyway.
\icmlauthor{Zhi Jing}{equal,first}
\icmlauthor{Enrico Quinto}{equal,second}
\icmlauthor{T\`ai Th\'ai}{equal,third}
\icmlauthor{Jonas Thumbs}{equal,fourth}
\icmlauthor{Baisu Zhou}{equal,fifth}
\end{icmlauthorlist}

% fill in your matrikelnummer, email address, degree, for each group member
\icmlaffiliation{first}{Matrikelnummer 12345678, MSc Machine Learning}
\icmlaffiliation{second}{Matrikelnummer 12345678, Exchange(?)}
\icmlaffiliation{third}{Matrikelnummer 12345678, MSc Machine Learning}
\icmlaffiliation{fourth}{Matrikelnummer 12345678, MSc Machine Learning}
\icmlaffiliation{fifth}{Matrikelnummer 7264384, MSc Machine Learning}

% put your email addresses here. You can use initials to save space, 
% e.g. if you are called Max Mustermann, you can use \icmlcorrespondingauthor{MM}{max.mustermann@uni-tuebingen.de}
% DO USE YOUR UNIVERSITY EMAIL ADDRESS!
\icmlcorrespondingauthor{ZJ}{first1.last1@uni-tuebingen.de} 
\icmlcorrespondingauthor{EQ}{first2.last2@uni-tuebingen.de}
\icmlcorrespondingauthor{TT}{first3.last3@uni-tuebingen.de}
\icmlcorrespondingauthor{JT}{first4.last4@uni-tuebingen.de}
\icmlcorrespondingauthor{BZ}{baisu.zhou@student.uni-tuebingen.de}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

%\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
TODO.
\end{abstract}

\section{Introduction}\label{sec:intro}

Measuring color accurately is a common problem in daily life, e.g. when a surface needs to be repainted in the same color. Devices that can carry out this task - so-called \emph{colorimeters} - are available commercially and usually cost several hundred dollars. 

On the other hand, there are smartphone apps that claim to offer the same service for free by using the built-in camera. A major challenge in this approach is how to deal with the effect of ambient light. \textcolor{lightgray}{Simply picking the color from a photo is not ideal because hue, saturation and brightness depend heavily on the lighting conditions. One way to address this issue is to capture the color of a known object (e.g. a white piece of paper) at the same time and use this to correct for the ambient light.}

In this study, we want to find out the best approach to correct for ambient light and determine how accurate the measurements from such an app can be. In order to do this, we collected a dataset, explored several algorithms for color correction and calculated the accuracy of the measurements with respect to a suitable metric.

\section{Data and Methods}\label{sec:methods}

We consider a deterministic scaling method and a data-driven model for color correction.

\subsection{Correction by Scaling}

Let $(R_\textup{m}, G_{\textup{m}}, B_\textup{m})$ be the measured RGB values of a color card.
For the scaling method, we assume that the measured color $(R_\textup{w}, G_{\textup{w}}, B_\textup{w})$ of the white reference is the brightness color one can measure under the ambient light.
To recover the full RGB space from the measurable color space $[0, R_\textup{w}] \times [0, G_\textup{w}] \times [0, B_\textup{w}]$, we apply a channelwise rescaling.
The corrected RGB values are given by
\begin{equation*}
    \begin{pmatrix}
        \widehat{R} \\ 
        \widehat{G} \\
        \widehat{B}
    \end{pmatrix} = \begin{pmatrix}
        \frac{255}{R_\textup{w}} & 0 & 0 \\
        0 & \frac{255}{G_\textup{w}} & 0 \\
        0 & 0 & \frac{255}{B_\textup{w}}
    \end{pmatrix}\begin{pmatrix}
        R_\textup{m} \\
        G_\textup{m} \\
        B_\textup{m}
    \end{pmatrix}.
\end{equation*}
This method was suggested by TODO:REF for colorimetry.

\subsection{Correction by Model}

The second method is to fit a regression model on our measured data.
For this method, we first need to transform the colors into a meaningful color space.
The RGB space is not suitable, because the Euclidean distance between RGB triples does not align with the perceived difference between colors.
In our analysis, we use the CIELAB (or $L^* a^* b^*$) color space, designed by the Commission Internationale de l’Éclairage (CIE)\footnote{
    In Enligh: International Commission on Illumination.
    Website: \url{https://cie.co.at/}.
} for colorimetric applications.
The $L^*$ coordinate represents lightness, while $a^*$ and $b^*$ control the hue.
CIELAB was designed to provide approximately perceptual uniformity, with scales comparable to those of color atlases such as the Munsell system, and with coordinate axes corresponding to Hering’s opponent-color theory \cite{oleari2015}.
This allows the use of Euclidean distance and related metrics, such as the mean squared error (MSE), to fit and analyze the model.

We consider a multi-target linear model defined by
\begin{equation} \label{eq:model}
\begin{split}
    \begin{pmatrix}
        \widehat{L^*} \\ 
        \widehat{a^*} \\
        \widehat{b^*}
    \end{pmatrix}
    =& \begin{pmatrix}
        A_{11} & A_{12} & A_{13} \\
        A_{21} & A_{22} & A_{23} \\
        A_{31} & A_{32} & A_{33}
    \end{pmatrix} \begin{pmatrix}
        L^*_\textup{m} \\
        a^*_\textup{m} \\
        b^*_\textup{m}
    \end{pmatrix} + \begin{pmatrix}
        b_1 \\
        b_2 \\
        b_3
    \end{pmatrix} \\
    &+ \begin{pmatrix}
        C_{11} & C_{12} & C_{13} \\
        C_{21} & C_{22} & C_{23} \\
        C_{31} & C_{32} & C_{33}
    \end{pmatrix} \begin{pmatrix}
        L^*_\textup{w} \\
        a^*_\textup{w} \\
        b^*_\textup{w}
    \end{pmatrix} \\
    &+ \begin{pmatrix}
        D_{11} & D_{12} \\
        D_{21} & D_{22} \\
        D_{31} & D_{32}
    \end{pmatrix} \begin{pmatrix}
        \textup{pitch} \\
        \textup{roll}
    \end{pmatrix},
\end{split}
\end{equation}
where $(L^*_\textup{m}, a^*_\textup{m}, b^*_\textup{m})$ and $(L^*_\textup{w}, a^*_\textup{w}, b^*_\textup{w})$ are the measured color of a color card and the white reference, respectively, and $A_{ij}, b_i, C_{ij}, D_{ij}$ are parameters.
The $L^* a^* b^*$ values for color cards and white reference are obtained by a non-linear transformation from the RGB values.
The transformation is intended for measurements under the standard indoor daylight condition D65, defined by CIE \cite{oleari2015}.
The lighting condition under which we collected data was an approximation to the D65 condition.
In \cref{tab:white-comparison} we compare the $L^* a^* b^*$ values of the white color under the D65 condition and the white reference used in our experiment.
The measured $L^*$ value is much lower than the D65 value, because the white reference in use is not perfectly white.
We assume the deviations in $a^*$ and $b^*$ from the standard case are sufficiently small and the transformation from RGB to $L^* a^* b^*$ is still valid.

\begin{table}
\caption{Comparison between the standard white in D65 and the white reference in our measurements (mean $\pm$ standard deviation).}
\label{tab:white-comparison}
\centering
\begin{tabular}{rccc}
    \toprule
    & $L^*$ & $a^*$ & $b^*$ \\
    \midrule
    \textbf{D65} & $100.000$ & $0.005260$ & $-0.010408$ \\
    \textbf{our} & $77.21 \pm 3.85$ & $0.30 \pm 0.93$ & $-3.53 \pm 2.07$ \\
    % \textbf{std} & $3.85248$ & $0.934964$ & $2.06641$ \\
    \bottomrule
\end{tabular}
\end{table}

Pitch and roll in \eqref{eq:model} provide information about the angle from which a picture was taken.
Our assumption is that the white reference can sufficiently characterize the ambient light, so that the additional information of pitch and roll contributes little to color correction.
We validate this assumption by comparing the full model \eqref{eq:model} with a reduced model with $D = 0$.

We fit the full and reduced model by minimizing the empirical risk associated with the loss function
\begin{equation*}
    \ell(y, \hat{y})
    = \left( L^* - \widehat{L^*} \right)^2 + \left( a^* - \widehat{a^*} \right)^2 + \left( b^* - \widehat{b^*} \right)^2,
\end{equation*}
where $y = (L^*, a^*, b^*)$ denotes the ground truth color and $\hat{y} = (\widehat{L^*}, \widehat{a^*}, \widehat{b^*})$ denotes the correction given by the model.
For simplicity, we refer to $\ell(y, \hat{y})$, the squared Euclidean distance between $y$ and $\hat{y}$, as the \emph{Euclidean error} of a correction, and the average of Euclidean error across training or test data as the \emph{mean squared error (MSE)}.\todo{
    Think about what to do with factor 3.
}
For the purpose of uncertainty quantification,
we construct bootstrap confidence intervals \cite{davison1997,efron1994} for the estimated coefficients.
We resample observations with replacement\footnote{%
    This corresponds to ``resampling cases'' in \citet{davison1997} and ``bootstrap pairs'' in \citet{efron1994}.
} and construct a percentile bootstrap confidence interval per parameter.

While our dataset covers only 24 colors, the correction methods ought to generalize to arbitrary colors.
We simulate the scenario of generalization to unseen colors by employing a $k$-fold cross-validation (CV) strategy.
For each $k \in \{1,\dots,20\}$, we reserve $k$ colors for testing and use the remaining $24 - k$ colors for training.\footnote{%
    Since our goal is not to identify model configurations of best generalization performance,
    but to analyze the model's behavior regarding unseen colors,
    we use all data in the CV process.
}
This CV scheme yields $\sum_{k=1}^{20} \binom{24}{k}$ trials in total.
As it is infeasible to exhaust all possible configurations, we consider two approaches to selecting the hold-out colors:
\begin{enumerate}[nosep]
    \item We randomly select $k$ colors.
    \item We manually select groups of colors based on their perceived tone (see \cref{tab:cv-folds}).
\end{enumerate}
Furthermore, we perform leave-one-out CV, training the model on all but the $k$-th color for $k = 1,\dots,24$ and testing it on the single color held out.


\begin{table}
\caption{Cross validation specification.}
\label{tab:cv-folds}
\centering
\begin{tabular}{ll}
    \toprule
    Test set & Colors \\
    \midrule
    Red & 7, 9, 12, 15 \\
    Green & 4, 6, 11, 14 \\
    Blue & 3, 5, 6, 8, 13, 18 \\
    Neutral & 19-24 \\
    \bottomrule
\end{tabular}
\end{table}


\section{Results}\label{sec:results}

\subsection{Scaling vs.\@ Model}

TODO: Error ECDFs for raw vs scaling vs model without pose vs model with pose.
Interpretation of coefficients.

\subsection{Cross Validation}

Scaling:
\begin{itemize}
    \item (Grid comparison: visual sanity check, no clear pattern cross colors. $\to$ visual abstract?)
    \item HSV KDE plots: slightly more quantitative, but still interpretable.
    \item Raw vs.\@ corrected RGB/LAB: scaling mostly corrects for brightness. The gray scale colors reflect the ambient light -- balanced light, as expected by the standard lighting condition.
\end{itemize}
KDE plots:
\begin{itemize}
    \item Both scaling and model mostly correct for brightness!
    \item Hue correction is minimal, possibly because of the ambient light.
\end{itemize}
Euclidean error (residual) ECDF: holistic view on performance.
\begin{itemize}
    \item Both scaling and model reduces max error significantly.
    Model reduces more.
    \item On average, model is only slightly better than scaling.
    \item White reference helps in model?
    \item With white reference, additional pose information does not change the error distribution, which supports our assumption that white reference is sufficient.
\end{itemize}

TODO:CV

\section{Discussion \& Conclusion}\label{sec:conclusion}

\begin{itemize}
    \item Limitations:
    \begin{itemize}
        \item Analysis focused on one lighting condition. We could not exactly reproduce D65 due to limited resources.
        In particular, professional colorimeter as comparison would be meaningful.
        \item White paper is not (255, 255, 255) -- bias towards underestimating brightness.
        \item Factors not considered: type of smartphone, distance to object.
        \item Error in color remains mostly uninterpretable.
        Only comparison, but no statement about whether one method is ``good enough.''
    \end{itemize}
\end{itemize}

\newpage

\section*{Contribution Statement}

TODO: Explain here, in one sentence per person, what each group member contributed.

% \section*{Notes} 

% Your entire report has a \textbf{hard page limit of 4 pages} excluding references and the contribution statement. (I.e. any pages beyond page 4 must only contain the contribution statement and references). Appendices are \emph{not} possible. But you can put additional material, like interactive visualizations or videos, on a githunb repo (use \href{https://github.com/pnkraemer/tueplots}{links} in your pdf to refer to them). Each report has to contain \textbf{at least three plots or visualizations}, and \textbf{cite at least two references}. More details about how to prepare the report, inclucing how to produce plots, cite correctly, and how to ideally structure your github repo, will be discussed in the lecture, where a rubric for the evaluation will also be provided.


\bibliography{bibliography}
\bibliographystyle{icml2025}

\end{document}

% This document was modified from the files available at https://icml.cc/Conferences/2025/AuthorInstructions
% the full copyright notice is available within the file icml2025.sty